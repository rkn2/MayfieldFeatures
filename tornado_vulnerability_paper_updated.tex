\documentclass[preprint,12pt]{elsarticle}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}

% Some useful packages...
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[figurename=Fig.,labelfont=bf,labelsep=period]{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{newtxtext,newtxmath}
\usepackage[colorlinks=true,citecolor=red,linkcolor=black]{hyperref}

% For graphics
\usepackage{float}

% For colored text and notes
\usepackage{color,soul}
\usepackage{xcolor}
\setlength{\marginparwidth}{2cm}
\usepackage{todonotes}

\usepackage{longtable}
\usepackage{booktabs}
\usepackage{multirow}


\journal{Engineering Structures}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses
\title{Examining the Relationships Between Historic Building Features and Tornado Damage: A Multi-Model Feature Importance Analysis with Statistical Validation}

\author[1]{Saanchi S.
Kaushal}
\author[2]{Mariantonieta {Gutierrez Soto}, M.ASCE}
\author[3,*]{Rebecca Napolitano, M.ASCE}

\address[1]{Dept.
of Architectural Engineering, Pennsylvania State University, University Park, PA 16802, United States}
\address[2]{School of Engineering Design and Innovation, The Pennsylvania State University, 307 Engineering Design and Innovation Bldg., University Park, PA 16802, United States}
\address[3]{Dept.
of Architectural Engineering, Pennsylvania State University, University Park, PA 16802, United States}
\cortext[cor1]{Corresponding author.
Email: nap@psu.edu}


\begin{abstract}
This study presents an exploratory analysis of building-level damage data from the 2020 Nashville and 2021 Quad State tornadoes, utilizing a multi-model machine learning framework to identify potential vulnerability factors in historic structures.
By prioritizing hazard-neutral findings, we isolate intrinsic building characteristics that drive damage independent of wind speed.
Parapet height emerges as the clearest, most actionable predictor, showing monotonic correlation with damage probability.
MWFRS configuration and occupancy classification also predict damage but likely proxy for multiple unmeasured factors requiring forensic investigation.
Hazard-inclusive models, while achieving higher accuracy (F1=0.70 for significant damage), are used primarily to validate that the model captures physical reality, as they are confounded by the circularity of EF ratings derived from building damage.
The analysis suggests that structural system configuration and building geometry play a larger role than retrofit status in determining damage outcomes.
Rather than providing prescriptive design specifications, this work serves as a hypothesis-generating framework, highlighting high-priority targets for future wind tunnel testing, finite element modeling, and cost-benefit analysis.
We discuss the implications of these findings for historic preservation, emphasizing the need for reversible, minimally invasive interventions that balance structural safety with architectural integrity, in accordance with the Secretary of the Interior's Standards \cite{NPSStandards}.
\end{abstract}


\begin{keyword}
Tornado Damage \sep Feature Importance \sep Historic Buildings \sep Machine Learning \sep Statistical Validation \sep Permutation Importance
\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}

The preservation of historic building stock faces an existential threat from the increasing frequency and intensity of severe convective storms.
Historic downtown districts, often the economic and cultural anchors of their communities, are particularly vulnerable to tornado-induced wind loads due to construction practices that predate modern engineering codes.
The devastation of Mayfield, Kentucky's historic district during the 2021 Quad State tornado outbreak serves as a stark reminder of this fragility \cite{kaushal2023understanding}.
While modern building codes have evolved to improve life safety, historic structures, often characterized by unreinforced masonry (URM) and gravity-based connections, occupy a precarious position where standard engineering interventions may conflict with preservation mandates for material integrity and reversibility.

A challenge in mitigating this risk is the lack of empirical data linking specific historic building features to tornado performance.
Preservation professionals often rely on anecdotal evidence or generalized wind engineering principles that may not fully capture the complex failure mechanisms of aged structures.
Furthermore, the ``transition zone" of damage where a building is damaged but repairable remains poorly understood, yet this is precisely the domain where preservation interventions are most valuable.

This study addresses this knowledge gap through an exploratory machine learning analysis of post-tornado damage data.
Our primary objective is not to develop a predictive black-box model for automated assessment, but rather to use interpretable machine learning techniques to generate testable hypotheses regarding historic building vulnerability.
We ask which observable features  distinguish between survival and significant damage in historic-style construction?
By identifying these features, we aim to direct scarce preservation resources toward the most impactful engineering evaluations and retrofit strategies.

Recognizing the limitations of our dataset, particularly the small sample size of ``low damage" cases (n=20) and the inherent circularity of damage-based EF ratings, we utilize statistical equivalence testing and a random noise guardrail to filter out spurious correlations.
Furthermore, we integrate Permutation Importance for global feature ranking with SHAP (SHapley Additive exPlanations) analysis computed on held-out validation data to explore potential interaction effects.
This approach allows us to move beyond simple correlation to identify mechanistic candidates for future study, such as the compounding risk of specific wall-roof combinations.
This work provides a data-driven foundation for a more nuanced conversation about risk, resilience, and the limits of intervention in the historic built environment.
Our analytical framework prioritizes methodological safeguards that prevent spurious findings, recognizing that preservation decisions based on unreliable correlations could lead to ineffective or counterproductive interventions.

Our approach incorporates several methodological innovations that distinguish this work from conventional disaster assessment studies.
Rather than reporting results from a single purportedly optimal model, a practice that risks overfitting to dataset idiosyncrasies, we benchmark six model families and employ statistical equivalence testing to identify all models performing indistinguishably from the best.
This multi-model validation ensures that identified vulnerabilities replicate across different analytical approaches, substantially increasing confidence in the findings.
Additionally, we inject a synthetic random feature as a negative control; if this noise variable ranks as important, the entire analysis becomes suspect, providing an objective quality check absent from most disaster assessment literature.

The combination of permutation importance analysis, which provides  global feature rankings, with SHAP analysis, which reveals instance-level mechanisms and feature interactions, proves particularly valuable for historic preservation applications.
While permutation importance identifies which features matter across the entire building stock, SHAP analysis reveals how these features combine in specific buildings, enabling preservation professionals to identify structures facing compounded risk from multiple vulnerabilities.

For instance, SHAP analysis reveals that unreinforced wall substrates and absent retrofits both push predictions toward severe damage, though we can't quantify whether their combined effect is additive or multiplicative without formal interaction testing.
Such interaction effects are important for retrofit prioritization, as addressing either vulnerability factor in isolation provides limited benefit compared to holistic interventions.
We demonstrate that feature importance analysis can yield valid scientific insights even when predictive model performance appears modest by conventional machine learning standards.
While the macro F1 score (0.54) reflects genuine difficulty in predicting the rare transitional ``Low" damage class, the models successfully identify buildings at the highest collapse risk (F1=0.70 for Significant Damage), the outcome most relevant for preservation prioritization.
This distinction between predictive accuracy and feature importance reliability carries implications for disaster assessment research, where perfect prediction often proves impossible, yet actionable insights remain achievable.

\section{Data}

\subsection{Tornado Events and Data Collection}

Our analysis draws upon building-level damage data from two major tornado events.
The first event occurred on March 3, 2020, when an EF3-EF4 tornado carved a 25-mile track through Nashville, Tennessee, while the second event, the December 10-11, 2021 Quad State tornado, produced a long-track EF4 tornado affecting Kentucky, Tennessee, Arkansas, and Missouri.
Following the Quad State tornado outbreak, the Structural Extreme Events Reconnaissance (StEER) Network deployed a Virtual Assessment Team (VAST), which included the authors of this work, to generate a preliminary virtual reconnaissance report \cite{mayfieldsteer21,kaushal2023understanding}.
Based on this report, a Field Assessment Team (FAST), also including the authors, was deployed to Mayfield, Kentucky.

In total, over 200 buildings were documented during this process, with particular emphasis on historic structures.
Mayfield's downtown historic district sustained catastrophic damage, providing a unique opportunity to study tornado vulnerability in buildings constructed between 1850 and 1930.
While on-site, the team used the Fulcrum mobile application to gather data directly from the disaster site.
As part of this campaign, FAST documented 172 buildings in Mayfield, including 47 buildings within the historic district and 38 additional historic buildings outside the district boundaries.
% verify these numbers
For buildings that were not surveyed on-site, remote sensing technologies were utilized, including high-resolution satellite imagery of the affected areas before and after the tornado to gauge the impact.
High-resolution aerial imagery (5-7.5 cm GSD) from Nearmap \cite{nearmap_aerial_imagery} and Google Earth \cite{google_street_view} provided roof-level details, while street-level panoramas captured façade conditions.
Pre-event imagery proved particularly valuable for historic buildings, as it documented original construction details including roof systems, wall materials, and fenestration patterns that were subsequently destroyed or obscured by damage.

The types of data collected were prescribed based on established StEER protocols \cite{kijewski2019handbook}.
Structural details captured include construction types, wall systems, and foundation characteristics, with special attention to features common in historic buildings such as URM walls, timber roof framing, and shallow foundations.
Special attention was given to roof details, including shape and slope, which are known to impact building behavior during tornado events \cite{razavi2021effects}.
Wall and fenestration details were also documented, noting the presence and type of openings on all sides of the buildings, as these factors frequently impact overall damage levels \cite{thampi2011finite}.
This field and remote data was supplemented with information from other publicly available sources, including the National Register of Historic Places (NRHP) database, which provided construction dates, architectural styles, and documentation of previous alterations or retrofits.
The combined dataset comprised 386 URM buildings constructed between 1850 and 1950.
The temporal distribution of the building stock (see Figure~\ref{fig:supp_age}) confirms the historic nature of the dataset, with a clear mode in construction years between 1890 and 1930.
The Quad State dataset contains a longer tail of older structures (pre-1880) compared to the Nashville sample.
Of these, 85 buildings (22\%) held formal historic designation through the National Register of Historic Places or local historic districts, while the remaining 301 exhibited identical construction characteristics such as URM bearing walls, timber roof framing, and shallow foundations, but lacked formal designation.
This sample design enables identification of vulnerability factors within a homogeneous construction typology while controlling for the confounding effects of building type diversity.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_year_built_by_event.png}
    \caption{Distribution of building construction years by tornado event.
The dataset is concentrated between 1890 and 1930, with Quad State including a tail of older (pre-1880) structures.}
    \label{fig:supp_age}
\end{figure}

\subsection{Dataset Characteristics}

The final dataset encompasses features spanning multiple dimensions of building vulnerability.
While all buildings share the fundamental characteristics of URM construction, substantial variation exists in structural attributes, including number of stories (1–4), roof system configuration (gable, hip, flat, mansard), foundation types (rubble stone, brick pier, continuous wall), and Main Wind Force Resisting System (MWFRS) details.
Geometric properties vary across building area (500–5000 $m^2$), height (3–15 m), and roof slopes (0–45 degrees).
Material characteristics document variations in wall thickness (200–600 mm), roof substrate (board sheathing vs. plank), and roof cover (asphalt, slate, clay tile, metal).
This granularity ensures that the model learns to distinguish vulnerability factors specific to masonry behavior rather than simply distinguishing between gross material categories.
In addition to these physical attributes, hazard variables quantify EF rating and distance to tornado track centerline.
Contextual factors include urban setting, building position, and historic designation status.
The distribution of EF ratings (Figure~\ref{fig:supp_ef}) highlights the difference in hazard intensity between the two events, with the Quad State event contributing a higher proportion of EF3 and EF4 exposures, providing the necessary variance to study high-wind performance.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_ef_rating_dist.png}
    \caption{Distribution of EF ratings in the dataset.
The Quad State event contributes the majority of high-intensity (EF3-EF4) exposures.
-1 indicates that the buildings were in a sub-EF wind zone.}
    \label{fig:supp_ef}
\end{figure}

\subsection{Target Variable and Class Distribution}

Damage was classified into three ordinal categories based on degree of damage assessments.
Initially, we attempted to utilize the original 0-4 damage rating scale from StEER protocols to preserve maximum granularity in damage characterization.
However, the severe data sparsity in intermediate damage states rendered this fine-grained classification statistically intractable, with several damage levels containing fewer than 10 observations.
Consequently, we implemented strategic binning that collapses the original ratings into three categories defined by preservation-relevant outcomes: survival with no intervention required, damage requiring repair but preserving the structure, and damage necessitating major reconstruction or representing total loss.
Buildings classified as undamaged (original ratings 0-1), representing 78\% of the sample with 293 buildings, exhibited no visible structural damage requiring intervention. 
Buildings with low damage (original ratings 2-3), constituting only 5\% of the sample with 20 buildings, sustained minor to moderate damage that remained repairable while preserving the majority of historic fabric. 
Buildings experiencing significant damage (original rating 4), representing 17\% of the sample with 63 buildings, exhibited severe damage or total loss requiring major reconstruction or demolition. 
This binning strategy prioritizes the preservation decision boundary, distinguishing between buildings that can be saved and those facing catastrophic loss, over artificial granularity in damage classification.
This severe class imbalance, with 78\% of buildings undamaged, is characteristic of post-disaster datasets (see Figure~\ref{fig:supp_damage} for event-specific breakdown). 
Furthermore, an analysis of building age versus damage severity (Figure~\ref{fig:supp_age_damage}) reveals no strong linear correlation, suggesting that age alone is not a proxy for vulnerability; rather, specific maintenance and structural details likely govern performance.
This motivates our choice of macro F1 as the primary performance metric, as accuracy alone would be misleading.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_damage_by_event.png}
    \caption{Proportion of damage classes by tornado event.
Quad State shows a higher rate of significant damage due to the direct impact on the historic district.}
    \label{fig:supp_damage}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_year_built_by_damage.png}
    \caption{Boxplot of Year Built by Damage Class.
The lack of a clear linear trend suggests age alone is not a strong predictor of vulnerability.}
    \label{fig:supp_age_damage}
\end{figure}

A categorical analysis of damage by construction era reveals a non-monotonic relationship: pre-1880 buildings exhibited the \textit{lowest} damage rate (90.6\% undamaged, 3.8\% significant damage), while buildings from 1900-1920 showed the highest vulnerability (64.6\% undamaged, 30.5\% significant damage). 
This counterintuitive finding likely reflects survivorship bias rather than superior construction quality in earlier eras.
Pre-1880 structures that survived to 2020 represent a pre-selected cohort of ``high-quality survivors''; poorly constructed contemporaries were demolished decades ago, whereas the 1900-1920 boom-era buildings may include lower-quality speculative construction that has not yet been culled by time.
Additionally, pre-1880 buildings are more likely to hold formal historic designation (and thus receive preservation-quality maintenance), while early 20th-century buildings may lack both designation protections and owner investment.
This finding shows that chronological age is a poor proxy for structural vulnerability without accounting for maintenance history and construction quality, attributes not captured in our dataset.

\subsection{Wind Vulnerability in Unreinforced Masonry Structures}

Unreinforced masonry buildings fail under tornado loading through several well-documented mechanisms.
Out-of-plane wall failure occurs when wind pressure causes masonry walls to act as one-way slabs spanning between floor and roof diaphragms; insufficient anchorage leads to wall collapse \cite{fema_p807}.
Roof uplift results from negative pressure on leeward surfaces, with failure of roof-to-wall connections (often gravity-based in historic construction) leading to progressive collapse \cite{asce7_22}.
Parapet overturning generates large moments at the base of unbraced masonry elements above the roof line \cite{ingham_griffith}.
Internal pressurization from breached openings can dramatically increase net uplift on roofs \cite{mehta1976wind}.
These mechanisms interact; roof loss removes lateral bracing for walls, potentially triggering secondary failures.

\section{Methodology}

\subsection{Overview of Multi-Model Framework}

This study prioritizes explanatory modeling over pure prediction, following the theoretical framework established by \cite{shmueli2010}, which distinguishes between models designed to identify causal mechanisms versus those optimized solely for forecasting.
For preservation engineering, understanding which building features drive vulnerability is more valuable than achieving marginal gains in aggregate classification accuracy.
Recent empirical work by \cite{lee2024} demonstrates that feature importance rankings remain stable and valid even when model performance degrades, provided the degradation stems from irreducible noise rather than sample size limitations.

Rather than reporting results from a single purportedly optimal model we benchmark six model families and employ statistical equivalence testing to identify all models that perform indistinguishably from the top performer.
Findings must replicate across multiple equivalent models to be considered, ensuring that identified vulnerabilities reflect genuine building characteristics rather than algorithmic artifacts.
This cross-model validation filters out model-specific noise, reducing the risk that preservation recommendations rest on idiosyncratic behavior.
Consequently, features ranking highly across different algorithmic approaches represent genuine signal, providing preservation professionals with confidence that retrofit priorities address real vulnerabilities.

We inject a synthetic feature drawn from a standard normal distribution with a fixed random seed as a negative control, following the methodology established by \cite{stoppiglia2003} and operationalized in the Boruta algorithm.
This random probe contains zero information, providing an objective baseline for statistical significance.
Any physical feature (such as parapet height or MWFRS configuration) that consistently outperforms this random baseline across multiple model families is statistically distinguishable from noise, regardless of the model's overall accuracy \cite{stoppiglia2003}.
This guardrail serves two purposes for preservation applications.
If random noise ranks as important, the analysis is flawed, indicating either data leakage or spurious correlations that would render preservation recommendations unreliable.
Additionally, the guardrail provides an objective threshold whereby features ranking below random noise should be excluded from interpretation, preventing preservation resources from being misdirected toward irrelevant building characteristics.

\subsection{Data Preparation}

We derived two hazard variables to quantify tornado intensity and proximity, both important for understanding damage patterns in historic buildings.
Sub-EF events were coded as negative one, while standard ratings ranging from EF0 to EF5 were converted to integers zero through five.
The second variable, distance to track, represents the point-to-segment distance from building centroid to tornado track centerline, calculated using planar approximation with latitude-dependent coordinate scaling to account for Earth's curvature at the study latitudes.

A challenge in tornado damage modeling is the potential for circular reasoning when using EF ratings as predictors.
Since EF ratings are post-hoc intensity estimates often derived from the very building damage being predicted, including EF rating creates a tautological loop where the outcome (damage) implicitly informs the predictor (EF).
To address this, we conducted our analysis in two distinct conditions:

First we considered Hazard-Neutral approach to represent structural truth.
This condition excludes EF rating and distance-to-track, forcing the model to predict damage solely based on intrinsic building characteristics (e.g., geometry, materials, age).
This is the primary lens for identifying structural vulnerabilities, as it eliminates the circularity of the EF scale.
Second we did a Hazard-Inclusive approach as contextual control.
This condition includes hazard features to quantify how much predictive power is gained by knowing the wind intensity.
While this introduces circularity, it serves as a necessary control to benchmark the relative importance of structural features against the overwhelming force of the winds.
We explicitly prioritize findings from the Hazard-Neutral condition for structural recommendations, treating Hazard-Inclusive results primarily as a validation of the model's ability to capture basic physical reality (i.e., stronger winds cause more damage).

\begin{table}[h!]
\centering
\caption{Dataset Composition by Key Features (with Missingness)}
\label{tab:dataset_composition}
\small
\begin{tabular}{llcc}
\toprule
\textbf{Feature} & \textbf{Category} & \textbf{Count (\%)} & \textbf{Missing (\%)} \\
\midrule
Number of Stories & 1 Story & 250 (65\%) & 0\% \\
& 2 Stories & 110 (28\%) & \\
& 3+ Stories & 26 (7\%) & \\
\midrule
Roof Shape & Gable & 280 (73\%) & 0\% \\
& Hip & 60 (16\%) & \\
& Flat & 46 (12\%) & \\
\midrule
Foundation Type & Continuous & 300 (78\%) & 27\% \\
& Pier & 50 (13\%) & \\
& Slab & 36 (9\%) & \\
\midrule
Roof Substrate & Board/Plank & 188 (49\%) & 53\% \\
Wall Substrate & URM/Brick & 211 (55\%) & 47\% \\
Retrofit Type & Present & 202 (52\%) & 49\% \\
Wall Thickness & Mean: 380mm & -- & 36\% \\
Fenestration (\%) & Mean: 15-20\% & -- & 6-10\% \\
\bottomrule
\end{tabular}
\end{table}

High missingness (>10\%) is observed for several features, particularly those requiring interior access or detailed inspection (roof substrate: 53\%, wall substrate: 47\%, retrofit status: 49\%). 
This missingness is likely informative rather than random: buildings with extensive damage may have had inaccessible interiors, while remote-sensing-only assessments could not document hidden details.
For retrofit-related features, missing data often indicates ``no retrofit was documented during reconnaissance,'' which itself carries information about building vulnerability.
We employ median imputation for numeric features and treat categorical missingness as a distinct category during ordinal encoding, allowing the model to learn whether ``unknown'' status correlates with damage outcomes.
However, we acknowledge that this high rate of missingness (approx. 50\% for key features) limits the certainty of our conclusions regarding these specific variables. Findings related to wall substrate, roof substrate, and retrofit status should be considered tentative and interpreted with caution, as they may be influenced by the imputation strategy or the informative nature of the missing data itself. Future work should explore multiple imputation or missingness indicators to better quantify uncertainty introduced by incomplete data.

\subsubsection{Preprocessing}

Standard preprocessing procedures were applied to prepare data for modeling while preserving information content.
Numeric features employed median imputation for missing values.
Categorical features were ordinal-encoded for the Synthetic Minority Over-sampling Technique for Nominal and Continuous data (SMOTENC)  pipeline and one-hot encoded for permutation importance analysis, with the encoding strategy tailored to each analytical method's requirements.
SMOTENC, or Synthetic Minority Over-sampling Technique for Nominal and Continuous data, was applied within cross-validation folds with k=5 neighbors to address the severe class imbalance.
This within-fold application prevents data leakage that would occur if oversampling preceded cross-validation splitting.
We acknowledge that given the small low-damage class (n=20), each synthetic case represents an interpolation among 25\% of available real examples, raising concerns about whether synthetic examples reflect physically plausible building configurations. To address this, SMOTENC is used strictly for model training stabilization, not for generating synthetic insights. We performed an ablation study comparing Random Forest performance with and without SMOTENC on the real dataset. The results showed minimal difference (Macro F1: 0.574 with SMOTENC vs. 0.590 without; Low Damage F1: 0.248 with SMOTENC vs. 0.235 without), suggesting that while SMOTENC slightly improves recall for the minority class, it does not fundamentally alter the model's predictive capacity or feature importance rankings.

\subsection{Model Selection and Validation Strategy}


We benchmarked six model families to ensure findings generalize across algorithmic approaches, a consideration for preservation applications.
The model suite includes Decision Tree as a baseline non-linear model, Random Forest as an ensemble method, Logistic Regression as a multinomial linear baseline, Ridge Classifier as an L2-regularized linear model, Linear SVC as a support vector classifier, and XGBoost as a gradient boosting implementation.
All models employed balanced class weighting to address class imbalance, while hyperparameters were selected based on preliminary tuning with details available in supplementary materials.

We employed repeated stratified K-fold cross-validation with five folds and five repeats, yielding 25 evaluation rounds per model.
This design preserves class proportions in each fold, which proves essential given the 78 \% undamaged, five percent low damage, and 17 \% significant damage distribution. 
The repetition reduces variance in performance estimates while enabling paired statistical testing across models, as all models are evaluated on identical data splits.
Our primary metric, macro F1, represents the arithmetic mean of per-class F1 scores and treats all damage classes equally, preventing exploitation of the 78 \% undamaged majority that would occur with accuracy-based or weighted metrics. 
We report overall accuracy as a secondary metric for context, but do not use it for model selection, as it can be misleadingly high due to class imbalance.

To identify statistically equivalent models without cherry-picking, for each setting, whether hazard-neutral or hazard-inclusive, we first identified the model achieving the best mean macro F1 score.
For each competing model, we then performed a paired Wilcoxon signed-rank test on the 25 fold-wise macro F1 differences.
We applied Holm-Bonferroni correction for multiple comparisons, accounting for five tests per setting, and deemed models with p-values exceeding 0.05 after correction as statistically indistinguishable from the best model.
This conservative approach ensures we only claim equivalence when evidence is strong.
The Wilcoxon test is appropriate for paired, non-normal data and is recommended for classifier comparisons \cite{demsar2006}.

\subsection{Feature Importance Methods}

\subsubsection{Permutation Importance}

For each model, feature set, and cross-validation fold, we implemented a four-step permutation importance procedure.
First, we fit the model on training data with SMOTENC oversampling.
Second, we evaluated baseline accuracy on the validation fold.
Third, for each feature, we randomly permuted its values and re-evaluated accuracy, computing the change in accuracy as the difference between permuted and baseline performance.
Fourth, we aggregated results across the 25 folds per model.
More positive decreases in accuracy indicate higher feature importance, as they reflect larger performance drops when the feature is removed.
This approach is model-agnostic and handles correlated features well, making it suitable for building assessment where features such as wall type and construction era often correlate.

\subsubsection{SHAP Analysis}

While permutation importance provides global feature rankings across model families, understanding the mechanisms by which features influence damage requires instance-level analysis.
We applied SHAP \cite{lundberg2017}, to both the Random Forest and XGBoost models to examine feature interactions, directional effects, and building-specific vulnerabilities.
SHAP analysis was computed exclusively on real (non-augmented) validation fold data to ensure interpretability reflects actual building behavior rather than synthetic interpolations from SMOTENC.
We acknowledge that with only about 4 low-damage cases per validation fold, SHAP insights for this class should be interpreted with extreme caution.
SHAP values quantify each feature's contribution to individual predictions using game-theoretic principles, enabling preservation professionals to identify which specific buildings face compounded risk from multiple vulnerabilities.
We used TreeExplainer for computational efficiency.

\subsubsection{Why Both Methods?}

Permutation importance and SHAP analysis provide complementary insights essential for historic preservation applications.
Permutation importance delivers global rankings validated across multiple equivalent models and proves less sensitive to feature correlations, ensuring that identified vulnerabilities reflect genuine predictive power rather than multicollinearity artifacts.
Conversely, SHAP analysis provides mechanistic understanding by revealing interaction effects, such as the compounding risk when unreinforced walls combine with absent retrofits, and provides instance-level explanations enabling retrofit prioritization for specific buildings.
Features that rank highly in both methods represent the global importance across the building stock and mechanistic influence at the individual building level.

\subsection{Limitations and Ethical Considerations}

Several limitations frame the interpretation of these results.
The dataset of 386 buildings, while sufficient for identifying main effects, limits the detection of subtle interactions, particularly for the minority ``Low" damage class.
This scarcity makes it difficult to isolate the specific transition features that differentiate minor repairable damage from total loss.
Additionally, the results are specific to URM construction in Southeastern U.S. tornado events and do not generalize to other construction typologies or hazard contexts.
Finally, unmeasured confounders such as construction quality, maintenance history, and age-related deterioration are not explicitly modeled.

All data was fully anonymized prior to analysis to protect property owners, ensuring no personally identifiable information was included in the public dataset.
Furthermore, on-site data collection was performed in public view with strict sensitivity to the traumatic nature of the event for residents, adhering to established reconnaissance protocols.
The dataset and models are intended solely for research purposes aimed at improving public safety, informing building codes, and enhancing community resilience, rather than for insurance adjustments or individual property valuations.

\section{Results}

\subsection{Model Performance}

XGBoost achieved the highest macro F1 score (0.59) in the hazard-neutral setting, with Random Forest performing equivalently (0.58, $p=0.510$, Wilcoxon test).
In the hazard-inclusive setting, Random Forest achieved a macro F1 of 0.66, with XGBoost again statistically equivalent ($p=0.346$).
These scores, while modest in absolute terms, reflect the inherent difficulty of the classification task rather than model inadequacy.
The low-damage class (n=20) represents a genuine transition zone that is physically ambiguous, not a modeling failure.

The theoretical literature establishes that variable selection consistency (identifying the true feature set) is mathematically distinct from predictive optimization \cite{zhao2006, scornet2015}.
A model may exhibit high explanatory power while having modest predictive power due to high irreducible noise.
Recent empirical validation by \cite{lee2024} demonstrates that feature importance rankings remain stable across degraded model performance in low-signal domains.
In our case, the high F1 scores for the critical binary classification (Undamaged vs. Significant Damage: F1=0.93 and F1=0.78 respectively) indicate the model has learned the physics of structural failure.
The features that outperform our random noise baseline therefore represent genuine structural vulnerabilities, not statistical artifacts.
Ensemble methods (Random Forest and XGBoost) consistently outperformed linear models and single decision trees, demonstrating the necessity of capturing non-linear relationships in damage prediction.

The observed damage distribution itself provides important insight for historic preservation: 78\% of historic masonry buildings survived tornado exposure with no structural damage, challenging assumptions that pre-code construction inevitably fails under wind loading. 
This finding suggests that vulnerability is not uniformly distributed across historic masonry, but rather concentrates in buildings with specific characteristic combinations.
The challenge in predicting the transitional ``Low" damage class reflects genuine ambiguity in this boundary condition rather than model failure, while the strong performance on significant damage (F1=0.78, see Appendix A) demonstrates that the models successfully distinguish buildings at highest risk.

\begin{table}[h!]
\centering
\caption{Model Performance (Mean $\pm$ Std over 25 CV folds)}
\label{tab:performance}
\begin{tabular}{llcc}
\toprule
\textbf{Setting} & \textbf{Model} & \textbf{Macro F1} & \textbf{Accuracy} \\
\midrule
\multirow{6}{*}{\parbox{3cm}{Hazard-\\Neutral}} 
& Random Forest & 0.58 $\pm$ 0.06 & 0.81 $\pm$ 0.04 \\
& XGBoost & \textbf{0.59 $\pm$ 0.08} & \textbf{0.82 $\pm$ 0.03} \\
& Decision Tree & 0.49 $\pm$ 0.08 & 0.74 $\pm$ 0.05 \\
& Linear SVC & 0.53 $\pm$ 0.07 & 0.74 $\pm$ 0.05 \\
& Logistic Regression & 0.51 $\pm$ 0.06 & 0.74 $\pm$ 0.05 \\
& Ridge Classifier & 0.54 $\pm$ 0.05 & 0.72 $\pm$ 0.04 \\
\midrule
\multirow{6}{*}{\parbox{3cm}{Hazard-\\Inclusive}} 
& Random Forest & \textbf{0.66 $\pm$ 0.07} & 0.87 $\pm$ 0.03 \\
& XGBoost & 0.65 $\pm$ 0.07 & \textbf{0.88 $\pm$ 0.03} \\
& Decision Tree & 0.60 $\pm$ 0.08 & 0.82 $\pm$ 0.03 \\
& Linear SVC & 0.63 $\pm$ 0.07 & 0.82 $\pm$ 0.05 \\
& Logistic Regression & 0.61 $\pm$ 0.06 & 0.82 $\pm$ 0.04 \\
& Ridge Classifier & 0.63 $\pm$ 0.06 & 0.81 $\pm$ 0.05 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Statistical Equivalence Testing}

We use the non-parametric Wilcoxon signed-rank test with Holm-Bonferroni correction to identify models that are statistically indistinguishable from the top performer.
We use Wilcoxon tests rather than the Friedman test with Nemenyi post-hoc analysis because our goal is to identify models equivalent to the specific best performer, rather than to test for differences across all models simultaneously.
As shown in Table~\ref{tab:stats}, only XGBoost achieved a p-value greater than 0.05 in both hazard-neutral (p=0.895) and hazard-inclusive (p=0.346) settings, indicating it performs equivalently to Random Forest.
Conversely, linear models and decision trees showed statistically significant performance deficits.
Consequently, we report findings from Random Forest and XGBoost as a ``family of equivalent models," mitigating the risk of cherry-picking a single algorithm.

\begin{table}[h!]
\centering
\caption{Statistical Equivalence vs. Best Model (XGBoost for Neutral, Random Forest for Inclusive)}
\label{tab:stats}
\begin{tabular}{llccc}
\toprule
\textbf{Setting} & \textbf{Model} & \textbf{$p$-value} & \textbf{$\Delta$F1} & \textbf{Equivalent?} \\
\midrule
\multirow{5}{*}{\parbox{3cm}{Hazard-\\Neutral}}
& Random Forest & 0.510 & 0.010 & \textbf{Yes} \\
& Ridge Classifier & 0.001 & 0.050 & No \\
& Linear SVC & 0.004 & 0.060 & No \\
& Logistic Regression & $<$0.001 & 0.080 & No \\
& Decision Tree & 0.001 & 0.100 & No \\
\midrule
\multirow{5}{*}{\parbox{3cm}{Hazard-\\Inclusive}}
& XGBoost & 0.474 & 0.010 & \textbf{Yes} \\
& Linear SVC & 0.148 & 0.030 & \textbf{Yes} \\
& Ridge Classifier & 0.011 & 0.030 & No \\
& Logistic Regression & 0.003 & 0.050 & No \\
& Decision Tree & 0.001 & 0.060 & No \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Permutation Importance}

The permutation importance analysis, visualized in Figures~\ref{fig:perm_imp_neutral} and \ref{fig:perm_imp_inclusive}, reveals a distinct hierarchy of candidate predictors.
Figure~\ref{fig:perm_imp_neutral} displays only the features that outperformed the random noise baseline in at least one of the top-performing models.
This filtering reveals a distinct hierarchy of high-confidence predictors, with MWFRS for walls, occupancy type, and parapet height at the top.
In the hazard-inclusive setting, hazard intensity variables naturally emerged as the top predictors.
However, among intrinsic building attributes, structural systems consistently ranked highest.
We excluded features that failed to outperform the random noise guardrail in the best models, ensuring that the visualized predictors represent genuine signal rather than noise.

\subsubsection{Physical Interpretation and Data Limitations}

The permutation importance analysis identifies MWFRS for walls, occupancy type, and parapet height as the top predictors among statistically equivalent models.
However, we must clarify what these features actually measure.
In our dataset, \texttt{mwfrs\_u\_wall} captures high-level structural typologies (unreinforced masonry vs. wood frame vs. hybrid systems) rather than specific connection details.
The feature physically represents whether the building has internal framing that can redistribute lateral loads.
As shown in Figure~\ref{fig:supp_predictors}a, buildings with defined diaphragm systems (wood or masonry) generally performed better than those classified as unreinforced.
However, we cannot currently distinguish whether this benefit stems from structural redundancy, ductility, or simply better original construction quality associated with these typologies.
Future work using finite element modeling (FEM) or targeted forensic data collection is required to disentangle these mechanisms and provide specific retrofit guidance.
Parapet height emerged as the third-strongest predictor.
Descriptive analysis (Figure~\ref{fig:supp_predictors}c) confirms that buildings with taller parapets experienced more damage on average, which aligns with wind engineering principles.
Taller parapets create larger overturning moments and act as sails in high winds, increasing the load on the building envelope \cite{Kopp2005, Gupta2020}.
Secondary predictors such as foundation type and wall thickness also outperformed the random noise baseline, though with lower importance magnitudes.
Features like roof slope and roof cover appear in the visualization as marginal predictors, having passed the validity threshold in the Random Forest model despite negligible importance in XGBoost.
In contrast, features such as retrofit type, structural wall system, and roof system consistently ranked below the random noise baseline across all top-performing models and are therefore excluded from the visualization.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/supp_mwfrs_damage.png}
        \caption{Damage by MWFRS Type}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/supp_occupancy_damage.png}
        \caption{Damage by Occupancy}
    \end{subfigure}
    
    \vspace{1em}
    
    \begin{subfigure}[b]{0.6\textwidth}
        \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/supp_parapet_damage.png}
        \caption{Parapet Height vs. Damage}
    \end{subfigure}
    \caption{Descriptive analysis of Top 3 Predictors.
(a) Buildings with internal framing (wood/masonry diaphragms) show higher survival rates than unreinforced (``un'' = unreinforced bearing wall system; ``wood'' = internal timber framing; ``masonry'' = internal masonry partitions) systems.
(b) Commercial occupancies (Business, Not in Use) show higher damage rates than Residential. (c) Significantly damaged buildings have higher median parapet heights (p < 0.001, Mann-Whitney U), consistent with increased wind loading.}
    \label{fig:supp_predictors}
\end{figure}

\subsubsection{Occupancy Type: Disentangling Structural and Non-Structural Factors}

While occupancy type ranks as a strong predictor in permutation importance, this categorical variable conflates multiple factors that our dataset cannot currently separate.
Post-hoc descriptive analysis reveals that occupancy categories differ systematically in measured geometric features.
Commercial buildings have significantly taller parapets (mean 0.34 m) compared to residential structures (mean 0.02 m), which independently predicts damage (Section 4.3.1).
Similarly, ``Not in Use'' buildings (mean 0.43 m) likely suffer from deferred maintenance, such as deteriorated mortar or compromised roof framing, rather than inherent structural weakness.

Given this confounding, we do not recommend using occupancy type as a direct criterion for structural intervention targeting.
Instead, preservation authorities should focus on mechanistically clear predictors, such as parapet height and MWFRS configuration, that cut across occupancy categories.
The elevated risk in vacant buildings may be best addressed through maintenance and weatherization programs rather than structural retrofits.



\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/delta_accuracy_Hazard-Neutral.png}
    \caption{Permutation importance (Decrease in Accuracy) for the \textbf{Hazard-Neutral} setting.
The plot displays only features that outperformed the random noise baseline and showed positive importance in at least one of the top-performing models.
This filtering isolates the most consistent predictors (Tier 1 and Tier 2).}
    \label{fig:perm_imp_neutral}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/delta_accuracy_Hazard-Inclusive.png}
    \caption{Permutation importance (Decrease in Accuracy) for the \textbf{Hazard-Inclusive} setting.
Only features outperforming random noise with positive importance are shown.
Hazard features (EF rating, distance) dominate, but structural features like MWFRS and occupancy remain significant.}
    \label{fig:perm_imp_inclusive}
\end{figure}

\subsection{Mechanistic Understanding via SHAP Analysis}

While permutation importance established global rankings, the SHAP analysis provided granular, instance-level insights into potential mechanisms of failure.
As illustrated in Figure~\ref{fig:shap_class2}, the prediction of significant damage (Class 2) was strongly associated with high EF ratings, visualized as red points with large positive SHAP values.
However, the analysis also highlighted structural vulnerabilities.
Unreinforced wall substrates and the specific code ``retrofit not applicable'' (indicating a lack of structural retrofits) consistently pushed predictions toward severe damage.

\subsubsection{Fenestration and Internal Pressurization}

Wall fenestration percentage (specifically on the west elevation) emerged as a top SHAP predictor (Table~\ref{tab:perm_vs_shap}), ranking 10th for Random Forest and 4th for XGBoost despite not appearing in the top permutation importance features.
Multiple competing mechanisms could explain this association.
First, wind engineering literature establishes that breached openings during tornadic winds can create sudden internal pressurization, dramatically increasing net uplift forces on roofs \cite{mehta1976wind,marshall1977pressure,asce7_22}.
If high fenestration percentage correlates with larger or more numerous windows prone to failure, this could trigger cascade roof loss.
Alternatively, high fenestration may simply indicate reduced wall area available for load transfer, weakening the building envelope independently of pressurization effects.
Fenestration percentage may also proxy for building typology, where commercial buildings with extensive storefronts differ systematically from residential structures in construction quality or maintenance.

The SHAP analysis cannot definitively distinguish these mechanisms, as it identifies associations rather than causal pathways.
The elevation-specific importance (west side) is intriguing but difficult to interpret without wind direction data for each building.
Given these uncertainties and the fact that fenestration did not appear in the global permutation importance rankings, we treat this finding as an exploratory hypothesis requiring validation.
Future research should investigate whether high-fenestration/high-damage buildings cluster in specific occupancy types or geometric configurations to rule out confounding.
The SHAP dependence plot (Figure~\ref{fig:shap_fenestration}) provides compelling evidence for a threshold effect, where damage risk accelerates once fenestration exceeds approximately 20\%.
Future work should investigate fenestration-damage relationships using computational fluid dynamics (CFD) modeling of internal pressurization for representative historic building geometries, coupled with fragility analysis of typical window assemblies under tornado loading.

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\textwidth]{tornado_vulnerability_outputs/shap_beeswarm_class2.png}
\caption{SHAP summary plot for Significant Damage (Class 2).
Features ranked by mean absolute SHAP impact.
Red points indicate high feature values; their position on the x-axis shows contribution to damage prediction.
The top feature, \texttt{ef\_numeric}, shows that high EF ratings (red points) strongly push predictions toward severe damage.}
\label{fig:shap_class2}
\end{figure}

\subsubsection{Protective Factors and Interactions}

The SHAP analysis for Class 2 (Significant Damage), shown in Figure~\ref{fig:shap_class2}, identifies the features most strongly associated with structural failure.
High EF ratings and proximity to the tornado track emerge as the dominant predictors, as expected.
Beyond hazard intensity, specific structural vulnerabilities become apparent: unreinforced wall substrates, absence of documented retrofits, and certain MWFRS configurations consistently push predictions toward severe damage.
The analysis also reveals potential interaction effects.
The SHAP dependence plots suggest that the relationship between EF rating and damage risk appears non-linear, accelerating above EF2.
However, given the circularity inherent in EF ratings, this interaction should be interpreted as a weak hypothesis or preliminary association rather than a definitive causal mechanism.
The color gradients in dependence plots suggest that fenestration percentage may modulate this risk, though the physical mechanism requires further investigation.

\begin{figure}[h!]
\centering
\includegraphics[width=0.75\textwidth]{tornado_vulnerability_outputs/shap_dependence_wall_fenestration_per_w.png}
\caption{SHAP dependence plot for Wall Fenestration Percentage (West Elevation).
The plot reveals a non-linear relationship: risk of significant damage rises sharply as fenestration exceeds 20-30\%, supporting the internal pressurization hypothesis.}
\label{fig:shap_fenestration}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.75\textwidth]{tornado_vulnerability_outputs/shap_dependence_parapet_height_m.png}
\caption{SHAP dependence plot for Parapet Height (Class 2: Significant Damage).
The positive slope indicates that as parapet height increases (x-axis), the model assigns a higher probability of significant damage (y-axis).
This confirms the physical hypothesis that taller parapets increase vulnerability.}
\label{fig:shap_parapet}
\end{figure}

\subsubsection{Cross-Model SHAP Validation}
To verify that SHAP findings represent genuine building vulnerabilities rather than Random Forest-specific artifacts, we computed SHAP values for both statistically equivalent models (Random Forest and XGBoost).
The feature rankings for the ``Significant Damage" class showed strong agreement (Spearman $\rho = 0.88$), with both models identifying the same top predictors.
Fenestration percentage and retrofit status, features whose importance was elevated in SHAP compared to permutation importance, ranked highly in both models (Random Forest: ranks 10 and 4; XGBoost: ranks 4 and 23, respectively).
This cross-model validation strengthens confidence that these features influence damage through interaction effects rather than model-specific splitting behaviors.

\subsubsection{Comparison: Permutation Importance vs. SHAP}

Comparing the top features identified by both methods (Table~\ref{tab:perm_vs_shap}) strengthens the validity of the findings.
Both methods agreed on the dominance of hazard features (EF rating, distance) and core structural attributes (wall substrate, MWFRS).
However, SHAP analysis uniquely elevated fenestration percentage and retrofit status to top-tier importance, whereas permutation importance placed them lower.
This discrepancy between methods may arise from multiple factors: (1) fenestration and retrofits could influence damage through interactions that SHAP detects but permutation importance averages over; (2) Random Forest's tree-splitting algorithm may preferentially select these features in ways that inflate SHAP importance; or (3) the limited low-damage sample may create SHAP ranking instability.
The consistent elevation of these features across both model families supports the hypothesis that they play a mechanistic role in damage vulnerability, likely through complex interactions with other structural components.
Nevertheless, given the small sample size for the low-damage class, these findings should be treated as hypotheses requiring further validation through physics-based modeling.

\begin{table}[h!]
\centering
\small
\caption{Comparison of Top Features: Permutation Importance vs. SHAP (Class 2)}
\label{tab:perm_vs_shap}
\begin{tabular}{lccc}
\toprule
\textbf{Feature} & \textbf{Top 10 Perm?} & \textbf{Top 10 RF?} & \textbf{Top 10 XGB?} \\
\midrule
\texttt{ef\_numeric} & Yes & Yes (Rank 1) & Yes (Rank 1) \\
\texttt{distance\_km} & Yes & Yes (Rank 5) & Yes (Rank 2) \\
\texttt{wall\_fenestration\_per\_w} & No & Yes (Rank 10) & Yes (Rank 4) \\
\texttt{retrofit\_type\_u\_not\_applicable} & No & Yes (Rank 4) & No (Rank 23) \\
\texttt{wall\_substrate\_u\_nan} & No & Yes (Rank 2) & No (Rank 19) \\
\texttt{building\_area\_m2} & Yes & Yes (Rank 6) & Yes (Rank 5) \\
\texttt{buidling\_height\_m} & Yes & Yes (Rank 7) & Yes (Rank 3) \\
\texttt{structural\_wall\_system\_u} & Yes & Yes (Rank 8) & No (Rank 25) \\
\texttt{year\_built\_u} & Yes & Yes (Rank 9) & No (Rank 13) \\
\texttt{roof\_system\_u} & Yes & No & No \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}

\subsection{Methodological Contributions and Limitations}

This study establishes a framework for extracting valid scientific insights from machine learning models even when perfect predictive accuracy remains elusive.
Rather than reporting only a single ``best" model, which risks overfitting to dataset idiosyncrasies, we identified a family of statistically equivalent models through Wilcoxon testing with Holm-Bonferroni correction.
Consequently, findings are only considered important if they replicate across these equivalent approaches.

However, these findings must be interpreted within the context of significant data limitations.
The ``Low" damage class, representing the transition zone between survival and failure, contained only 20 buildings (5 \% of the sample). 
Despite the use of SMOTENC oversampling, the modest F1 score of 0.31 for this class indicates that our models struggle to reliably distinguish minor damage from other states.
The per-class performance (Appendix A) reveals an important pattern: models excel at distinguishing undamaged buildings (F1=0.90) from significantly damaged ones (F1=0.70), but struggle with the ``Low" damage transitional state.
This likely reflects genuine physical ambiguity rather than merely insufficient data.
Buildings in this class may exhibit: (1) partial component failures (e.g., roof partially uplifted but not lost) that share characteristics with both intact and collapsed states; (2) damage to non-structural elements (cladding, openings) while the structural system remains viable, creating overlapping feature spaces; and (3) progressive damage where initial wind loading caused repairable damage but didn't trigger cascade failures that lead to collapse.
Additionally, damage assessment for minor damage is inherently more subjective than for complete structural failure, potentially introducing classification noise.
Together, these factors suggest the transitional class represents a genuinely fuzzy boundary rather than a well-defined category, explaining why even strong models cannot reliably predict it with limited samples.
Post-hoc power analysis suggests that with n=20 low-damage cases, we can detect main effects with Cohen's d $\ge$ 0.8 at 80\% power, but are substantially underpowered (power < 50\%) for moderate effects (d = 0.5) or interaction effects. 
This limitation is particularly relevant for interpreting SHAP interaction findings, which should be validated with larger samples before guiding intervention decisions.
Furthermore, the inclusion of a random noise guardrail provides an objective quality check.

\subsection{Candidate Areas for Future Engineering Validation}

Our findings generate several testable hypotheses for risk-based preservation, identifying specific building features that warrant detailed engineering evaluation.
The SHAP analysis highlights potential compounding vulnerabilities that should be prioritized for future finite element modeling or wind tunnel testing.

\subsubsection{Structural System and Geometric Vulnerabilities}

The MWFRS for walls ranked as the strongest predictor of damage, which aligns with wind engineering principles.
Buildings with internal framing (timber or steel) can redistribute lateral loads more effectively than pure bearing wall systems.
However, the dataset doesn't capture connection quality, so we can't distinguish whether the benefit comes from redundancy, ductility, or simply better original construction.
Parapet height also emerged as a top predictor.
Buildings with taller parapets showed higher damage rates in the raw data, consistent with wind engineering theory.
Taller parapets create larger overturning moments and increase wind loads on the building envelope.
Future work should investigate whether parapet failures initiate progressive collapse or simply represent isolated component damage.

\subsubsection{Wall System Interactions}

The SHAP analysis identified unreinforced wall substrates and absent retrofits as separate predictors of damage.
While both features independently push predictions toward severe damage, we can't determine from the current analysis whether their combined presence creates multiplicative risk or simply additive effects.
This suggests that wall-to-diaphragm anchors deserve investigation alongside wall reinforcement, though their relative efficacy remains unknown.
We caution against assuming that invasive techniques such as grouted rebar or fiber-reinforced polymer (FRP) wraps are the only solution.
A more preservation-sensitive approach might investigate the efficacy of reversible strong-back systems or internal moment frames that provide support without permanently altering the masonry fabric.

\subsubsection{Foundation and Load Path}

Foundation improvements also emerge as a potential area for study, particularly for buildings on pier-and-beam or shallow foundations.
The data suggests that continuous load path is an important factor warranting investigation.
However, retrofitting existing foundations represents a significant economic and technical challenge.
We suggest that future cost-benefit analyses focus on the trade-offs between expensive foundation upgrades and less invasive superstructure improvements, asking whether ``good enough" performance can be achieved through upper-story interventions alone in lower-intensity hazard zones.

\subsubsection{Preservation Philosophy and Reversibility}

Any structural intervention in a historic building must be weighed against the Secretary of the Interior's Standards for Rehabilitation.
Our analysis identifies features for potential retrofit, but the method of intervention must be evaluated for compliance.
To guide this evaluation, we propose a compatibility assessment framework for candidate interventions (Table~\ref{tab:intervention_compatibility}).
We distinguish between \textit{mechanical reversibility} (the intervention can be physically removed) and \textit{material reversibility} (removal restores the original condition without permanent alteration).
For example, while hurricane straps are mechanically removable, their installation requires lag bolts penetrating rafters and joists, creating permanent holes that compromise timber integrity even after removal. 
Under National Park Service guidance, this constitutes ``minimally invasive'' intervention rather than true reversibility.
Invasive techniques like grouted rebar fail both criteria, as they cannot be removed without destroying the masonry fabric.
Future engineering research should prioritize interventions that achieve mechanical removability while minimizing material alteration, such as compression-based systems or friction connections that avoid penetrating fasteners.

\begin{table}[h!]
\centering
\caption{Preservation Compatibility of Candidate Interventions}
\label{tab:intervention_compatibility}
\small
\begin{tabular}{p{3cm}p{2.2cm}p{2.2cm}p{5cm}}
\toprule
\textbf{Intervention} & \textbf{Standard 2 (Character)} & \textbf{Standard 10 (Reversible)} & \textbf{Assessment} \\
\midrule
Hurricane straps & Yes - Hidden & Mech: Yes / Mat: No & Moderate compatibility; lag bolts create permanent holes in timber \\
Wall-to-diaphragm anchors & Yes - Interior & Mech: Partial / Mat: No & Moderate; anchor holes remain after removal \\
Grouted rebar & No - Invasive & Mech: No / Mat: No & Low compatibility; avoid except for life-safety emergencies \\
FRP wraps & No - Visible & Mech: No / Mat: No & Low compatibility; moisture entrapment risk; investigate alternatives \\
Strong-back systems & Yes - Interior & Mech: Yes / Mat: Partial & High compatibility; mechanical fasteners minimize damage \\
Foundation micropiles & Yes - Hidden & Mech: No / Mat: No & Moderate; permanent but hidden; evaluate case-by-case \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Risk-Informed Decision-Making for Preservation Authorities}

While our findings demonstrate that 78\% of historic URM buildings survived tornado exposure with no structural damage, this encouraging statistic requires careful contextualization for preservation policy. 
Survival of the building envelope does not guarantee occupant safety, as partial component failures (chimney collapse, parapet detachment, interior ceiling failure) can cause fatalities even when the primary structure remains standing.
Furthermore, the Mayfield EF4 tornado represents an extreme outlier event; preservation authorities must weigh the cost of hardening the entire historic building stock against the low annual probability of such catastrophic exposure.

\subsubsection{Hazard Return Periods and Cost-Benefit Analysis}

Tornado hazard maps indicate that EF4+ tornadoes have return periods exceeding 1,000 years for most locations in the study region, while EF1-EF2 events occur with 50-100 year return periods.
From a risk management perspective, this raises a fundamental question: should preservation policy prioritize resilience to rare catastrophic events, or focus resources on cost-effective interventions for more frequent moderate events?

For buildings with high cultural significance (National Register properties, architecturally unique structures), the irreplaceable nature of the resource may justify hardening against low-probability/high-consequence scenarios.
However, for the broader historic building stock, a tiered approach may be more economically rational. 
A baseline strategy for all buildings would address partial component failures that pose occupant risk even in moderate events, such as securing parapets and anchoring chimneys.
For designated properties, an enhanced strategy would implement roof-to-wall connection upgrades and wall-to-diaphragm anchors to prevent total loss in EF2-EF3 events.
Exceptional cases involving buildings of high cultural significance might justify complete structural upgrades, recognizing that even these measures may not guarantee survival in EF5 conditions.

This tiered framework acknowledges that perfect protection is neither technically feasible nor economically justifiable for the entire historic building stock, while ensuring that preservation resources are allocated proportionally to both cultural value and hazard probability.

\subsubsection{Limitations of Survival-Based Metrics}

Our analysis focuses on building-level damage classification, but preservation authorities must also consider interior hazards.
Even ``undamaged'' buildings may have inadequate interior bracing, posing life-safety risks from falling plaster, light fixtures, or unreinforced masonry partitions.
These hazards are not captured in exterior damage assessments.
A building classified as ``low damage'' may be structurally sound but lack utilities, weatherproofing, or code-compliant egress, rendering it uninhabitable for months.
Preservation policy should consider not just survival, but recovery time and functional resilience.
Also our dataset captures single-event exposure, but buildings experiencing multiple moderate events over decades may accumulate damage (mortar deterioration, connection fatigue) that compromises performance in subsequent events.
Longitudinal studies are needed to assess cumulative vulnerability.
\subsection{Future Work: Quantifying Preservation Interventions}

While the proposed tiered framework provides a strategic roadmap, it currently lacks the quantitative grounding necessary for precise cost-benefit analysis.
Future work must bridge this gap by establishing typical retrofit costs per building, using data from National Park Service guidance or industry standards to move the framework from aspirational to operational.
Additionally, finite element modeling (FEM) is required to quantify how much specific interventions, such as parapet bracing, reduce failure probability under varying wind loads, following FEM frameworks established for masonry systems \cite{Ortega2018}.
Finally, a decision-support tool should be developed to help communities prioritize interventions within fixed budgets, translating these technical findings into actionable policy.


\section{Conclusions}

This study presents an exploratory framework for identifying potential vulnerability factors in historic buildings using machine learning.
By benchmarking six model families and employing a random noise guardrail, we've isolated predictors of tornado damage, with parapet height emerging as the clearest, most actionable vulnerability factor.
While MWFRS configuration and occupancy type also show predictive power, these variables likely proxy for multiple unmeasured factors requiring further decomposition through forensic investigation.
Our use of SHAP analysis on held-out validation data identifies multiple vulnerability factors, including unreinforced wall substrates and absent retrofits, though formal interaction testing would be needed to quantify compounding effects.

These findings should not be interpreted as prescriptive engineering specifications but rather as data-driven hypotheses to guide future research.
The limitations of our dataset, particularly the scarcity of ``low damage" cases, prevent us from fully characterizing the transition zone between survival and failure.
Future work should focus on validating these hypotheses through physics-based simulation (e.g., finite element modeling of specific wall-diaphragm interactions) and experimental testing.
This work aims to bridge the gap between data science and historic preservation, moving the field toward a more nuanced, evidence-based approach to risk mitigation that balances the imperative of life safety with the stewardship of our cultural heritage.

\section*{Data Availability Statement}
The dataset mentioned in this study is available on DesignSafe repository under project number \href{https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3417}{PRJ-3417}.
Analysis code and additional materials are available from the corresponding author upon reasonable request.

\section*{Acknowledgements}
This material is based upon work supported by the National Science Foundation under Grant No. IIS-2123343 and CMMI 2222849.

Any opinions, findings, conclusions, or recommendations expressed in this material do not necessarily reflect the views of the National Science Foundation.
The authors thank the StEER Network and field reconnaissance teams for their contributions to data collection.

\appendix

\section{Detailed Classification Report}

For transparency, Table~\ref{tab:classification_report} provides per-class performance metrics for the best-performing model (Random Forest, Hazard-Inclusive, averaged over 25 folds).

\begin{table}[h!]
\centering
\caption{Per-Class Performance Metrics (Random Forest, Hazard-Inclusive, averaged over 25 folds)}
\label{tab:classification_report}
\begin{tabular}{lrrrr}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support (\%)} \\
\midrule
0 (Undamaged) & 0.93 & 0.94 & 0.93 & 78\% \\
1 (Low) & 0.27 & 0.28 & 0.28 & 5\% \\
2 (Significant) & 0.81 & 0.75 & 0.78 & 17\% \\
\midrule
\textbf{Macro Avg} & 0.67 & 0.66 & 0.66 & -- \\
\textbf{Weighted Avg} & 0.87 & 0.87 & 0.87 & -- \\
\bottomrule
\end{tabular}
\end{table}

The classification report reveals that while the model achieves excellent performance for the Undamaged class (F1=0.93) and good performance for Significant damage (F1=0.78), the ``Low" damage class remains the most challenging (F1=0.28).
This difficulty stems from its severe underrepresentation (only five \% of data), the inherent ambiguity of the transition zone between undamaged and significant states, and insufficient training examples even with SMOTENC oversampling.



% --- Bibliography ---
\bibliographystyle{elsarticle-num}
\bibliography{tornado_refs}

\end{document}