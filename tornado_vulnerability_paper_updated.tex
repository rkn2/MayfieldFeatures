\documentclass[preprint,12pt]{elsarticle}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}

% Some useful packages...
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage[figurename=Fig.,labelfont=bf,labelsep=period]{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{newtxtext,newtxmath}
\usepackage[colorlinks=true,citecolor=red,linkcolor=black]{hyperref}

% For graphics
\usepackage{float}

% For colored text and notes
\usepackage{color,soul}
\usepackage{xcolor}
\setlength{\marginparwidth}{2cm}
\usepackage{todonotes}

\usepackage{longtable}
\usepackage{booktabs}
\usepackage{multirow}


\journal{Engineering Structures}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses
\title{Examining the Relationships Between Historic Building Features and Tornado Damage: A Multi-Model Feature Importance Analysis with Statistical Validation}

\author[1]{Saanchi S. Kaushal}
\author[2]{Mariantonieta {Gutierrez Soto}, M.ASCE}
\author[3,*]{Rebecca Napolitano, M.ASCE}

\address[1]{Dept. of Architectural Engineering, Pennsylvania State University, University Park, PA 16802, United States}
\address[2]{School of Engineering Design and Innovation, The Pennsylvania State University, 307 Engineering Design and Innovation Bldg., University Park, PA 16802, United States}
\address[3]{Dept. of Architectural Engineering, Pennsylvania State University, University Park, PA 16802, United States}
\cortext[cor1]{Corresponding author. Email: nap@psu.edu}


\begin{abstract}
This study presents an exploratory analysis of building-level damage data from the 2020 Nashville and 2021 Quad State tornadoes, utilizing a multi-model machine learning framework to identify potential vulnerability factors in historic structures. 
By benchmarking six model families with random noise guardrail validation, we identify candidate damage predictors in a severely imbalanced dataset (78 \% undamaged, 5 \% low damage, 17 \% significant damage). While the overall macro F1 score is 0.54 due to the model's struggle with the ambiguous 'low damage' class (F1=0.31), our models achieve strong performance on the preservation outcome which is identifying buildings at risk of significant damage (F1=0.70). 
This suggests the framework is effective for prioritizing buildings at risk of catastrophic loss, even if the transition zone remains fuzzy. 
Our findings identify roof system characteristics and wall-to-diaphragm connections as candidate predictors warranting detailed engineering evaluation. Specifically, the analysis suggests that URM walls without retrofits may face compounded risks, while specific roof geometries appear to correlate with improved survival rates. 
Rather than providing prescriptive design specifications, this work serves as a hypothesis-generating framework, highlighting high-priority targets for future wind tunnel testing, finite element modeling, and cost-benefit analysis. 
We discuss the implications of these findings for historic preservation, emphasizing the need for reversible, minimally invasive interventions that balance structural safety with architectural integrity.
\end{abstract}


\begin{keyword}
Tornado Damage \sep Feature Importance \sep Historic Buildings \sep Machine Learning \sep Statistical Validation \sep Permutation Importance
\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introduction}

The preservation of historic building stock faces an existential threat from the increasing frequency and intensity of severe convective storms. 
Historic downtown districts, often the economic and cultural anchors of their communities, are particularly vulnerable to tornado-induced wind loads due to construction practices that predate modern engineering codes. 
The devastation of Mayfield, Kentucky's historic district during the 2021 Quad State tornado outbreak serves as a stark reminder of this fragility. 
While modern building codes have evolved to improve life safety, historic structures, often characterized by unreinforced masonry (URM) and gravity-based connections, occupy a precarious position where standard engineering interventions may conflict with preservation mandates for material integrity and reversibility.

A challenge in mitigating this risk is the lack of empirical data linking specific historic building features to tornado performance. Preservation professionals often rely on anecdotal evidence or generalized wind engineering principles that may not fully capture the complex failure mechanisms of aged structures. 
Furthermore, the ``transition zone" of damage where a building is damaged but repairable remains poorly understood, yet this is precisely the domain where preservation interventions are most valuable.

This study addresses this knowledge gap through an exploratory machine learning analysis of post-tornado damage data. 
Our primary objective is not to develop a predictive black-box model for automated assessment, but rather to use interpretable machine learning techniques to generate testable hypotheses regarding historic building vulnerability. 
We ask which observable features  distinguish between survival and significant damage in historic-style construction? 
By identifying these features, we aim to direct scarce preservation resources toward the most impactful engineering evaluations and retrofit strategies.

Recognizing the limitations of our dataset—particularly the small sample size of ``low damage" cases (n=20) and the inherent circularity of damage-based EF ratings—we utilize statistical equivalence testing and a random noise guardrail to filter out spurious correlations. 
Furthermore, we integrate Permutation Importance for global feature ranking with SHAP (SHapley Additive exPlanations) analysis computed on held-out validation data to explore potential interaction effects. 
This approach allows us to move beyond simple correlation to identify mechanistic candidates for future study, such as the compounding risk of specific wall-roof combinations. 
Ultimately, this work provides a data-driven foundation for a more nuanced conversation about risk, resilience, and the limits of intervention in the historic built environment. 
Importantly, our analytical framework prioritizes methodological safeguards that prevent spurious findings, recognizing that preservation decisions based on unreliable correlations could lead to ineffective or counterproductive interventions.

Our approach incorporates several methodological innovations that distinguish this work from conventional disaster assessment studies. 
Rather than reporting results from a single purportedly optimal model, a practice that risks overfitting to dataset idiosyncrasies, we benchmark six model families and employ statistical equivalence testing to identify all models performing indistinguishably from the best. 
This multi-model validation ensures that identified vulnerabilities replicate across different analytical approaches, substantially increasing confidence in the findings. 
Additionally, we inject a synthetic random feature as a negative control; if this noise variable ranks as important, the entire analysis becomes suspect, providing an objective quality check absent from most disaster assessment literature. 
The combination of permutation importance analysis, which provides  global feature rankings, with SHAP analysis, which reveals instance-level mechanisms and feature interactions, proves particularly valuable for historic preservation applications. 
While permutation importance identifies which features matter across the entire building stock, SHAP analysis reveals how these features combine in specific buildings, enabling preservation professionals to identify structures facing compounded risk from multiple vulnerabilities.

For instance, our analysis demonstrates that URM walls alone increase damage risk moderately, but when combined with absent or inadequate retrofits, the risk compounds synergistically rather than additively. 
Such interaction effects are important for retrofit prioritization, as addressing either vulnerability factor in isolation provides limited benefit compared to holistic interventions. 
We demonstrate that feature importance analysis can yield valid scientific insights even when predictive model performance appears modest by conventional machine learning standards. 
While the macro F1 score (0.54) reflects genuine difficulty in predicting the rare transitional ``Low" damage class, the models successfully identify buildings at the highest collapse risk (F1=0.70 for Significant Damage), the outcome most relevant for preservation prioritization. 
This distinction between predictive accuracy and feature importance reliability carries implications for disaster assessment research, where perfect prediction often proves impossible, yet actionable insights remain achievable.

\section{Data}

\subsection{Tornado Events and Data Collection}

Our analysis draws upon building-level damage data from two major tornado events. 
The first event occurred on March 3, 2020, when an EF3-EF4 tornado carved a 25-mile track through Nashville, Tennessee, while the second event, the December 10-11, 2021 Quad State tornado, produced a long-track EF4 tornado affecting Kentucky, Tennessee, Arkansas, and Missouri. 
The Quad State event proved particularly significant for historic preservation research, as it devastated Mayfield, Kentucky's downtown historic district, which had been listed on the National Register of Historic Places. 
Following the Quad State tornado outbreak, the Structural Extreme Events Reconnaissance (StEER) Network deployed a Virtual Assessment Team (VAST), which included the authors of this work, to generate a preliminary virtual reconnaissance report. 
Based on this report, a Field Assessment Team (FAST), also including the authors, was deployed to Mayfield, Kentucky.

In total, over 200 buildings were documented during this process, with particular emphasis on historic structures. 
Mayfield's downtown historic district sustained catastrophic damage, providing a unique opportunity to study tornado vulnerability in buildings constructed between 1850 and 1930. 
While on-site, the team used the Fulcrum mobile application to gather data directly from the disaster site. As part of this campaign, FAST documented 172 buildings in Mayfield, including 47 buildings within the historic district and 38 additional historic buildings outside the district boundaries.
For buildings that were not surveyed on-site, remote sensing technologies were utilized, including high-resolution satellite imagery of the affected areas before and after the tornado to gauge the impact. This was complemented by aerial photography from Nearmap \cite{nearmap_aerial_imagery} and Google Street View \cite{google_street_view}. 
Pre-event imagery proved particularly valuable for historic buildings, as it documented original construction details including roof systems, wall materials, and fenestration patterns that were subsequently destroyed or obscured by damage.

The types of data collected were prescribed based on established StEER protocols \cite{kijewski2019handbook}. Structural details captured include construction types, wall systems, and foundation characteristics, with special attention to features common in historic buildings such as URM walls, timber roof framing, and shallow foundations. 
Special attention was given to roof details, including shape and slope, which are known to impact building behavior during tornado events \cite{razavi2021effects}.
Wall and fenestration details were also documented, noting the presence and type of openings on all sides of the buildings, as these factors frequently impact overall damage levels \cite{thampi2011finite}. 
This field and remote data was supplemented with information from other publicly available sources, including the National Register of Historic Places (NRHP) database, which provided construction dates, architectural styles, and documentation of previous alterations or retrofits. 
The combined dataset comprised 386 URM buildings constructed between 1850 and 1950. 
The temporal distribution of the building stock (see Figure~\ref{fig:supp_age}) confirms the historic nature of the dataset, with a clear mode in construction years between 1890 and 1930. 
Interestingly, the Quad State dataset contains a longer tail of older structures (pre-1880) compared to the Nashville sample. Of these, 85 buildings (22\%) held formal historic designation through the National Register of Historic Places or local historic districts, while the remaining 301 exhibited identical construction characteristics such as URM bearing walls, timber roof framing, and shallow foundations, but lacked formal designation. 
This sample design enables identification of vulnerability factors within a homogeneous construction typology while controlling for the confounding effects of building type diversity.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_year_built_by_event.png}
    \caption{Distribution of building construction years by tornado event. The dataset is concentrated between 1890 and 1930, with Quad State including a tail of older (pre-1880) structures.}
    \label{fig:supp_age}
\end{figure}

\subsection{Dataset Characteristics}

The final dataset encompasses features spanning multiple dimensions of building vulnerability. 
While all buildings share the fundamental characteristics of URM construction, substantial variation exists in structural attributes, including number of stories (1–4), roof system configuration (gable, hip, flat, mansard), foundation types (rubble stone, brick pier, continuous wall), and Main Wind Force Resisting System (MWFRS) details. 
Geometric properties vary across building area (500–5000 $m^2$), height (3–15 m), and roof slopes (0–45 degrees). 
Material characteristics document variations in wall thickness (200–600 mm), roof substrate (board sheathing vs. plank), and roof cover (asphalt, slate, clay tile, metal). 
This granularity ensures that the model learns to distinguish vulnerability factors specific to masonry behavior rather than simply distinguishing between gross material categories.
In addition to these physical attributes, hazard variables quantify EF rating and distance to tornado track centerline. 
Contextual factors include urban setting, building position, and historic designation status. 
The distribution of EF ratings (Figure~\ref{fig:supp_ef}) highlights the difference in hazard intensity between the two events, with the Quad State event contributing a higher proportion of EF3 and EF4 exposures, providing the necessary variance to study high-wind performance.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_ef_rating_dist.png}
    \caption{Distribution of EF ratings in the dataset. The Quad State event contributes the majority of high-intensity (EF3-EF4) exposures. -1 indicates that the buildings were in a sub-EF wind zone.}
    \label{fig:supp_ef}
\end{figure}

\subsection{Target Variable and Class Distribution}

Damage was classified into three ordinal categories based on degree of damage assessments. 
Initially, we attempted to utilize the original 0-5 damage rating scale from StEER protocols to preserve maximum granularity in damage characterization. 
However, the severe data sparsity in intermediate damage states rendered this fine-grained classification statistically intractable, with several damage levels containing fewer than 10 observations. 
Consequently, we implemented strategic binning that collapses the original ratings into three categories defined by preservation-relevant outcomes: survival with no intervention required, damage requiring repair but preserving the structure, and damage necessitating major reconstruction or representing total loss.
Buildings classified as undamaged (original ratings 0-1), representing 78\% of the sample with 293 buildings, exhibited no visible structural damage requiring intervention. 
Buildings with low damage (original ratings 2-3), constituting only 5\% of the sample with 20 buildings, sustained minor to moderate damage that remained repairable while preserving the majority of historic fabric. 
Buildings experiencing significant damage (original ratings 4-5), representing 17\% of the sample with 63 buildings, exhibited severe damage or total loss requiring major reconstruction or demolition. 
This binning strategy prioritizes the preservation decision boundary, distinguishing between buildings that can be saved and those facing catastrophic loss, over artificial granularity in damage classification.
This severe class imbalance, with 78\% of buildings undamaged, is characteristic of post-disaster datasets (see Figure~\ref{fig:supp_damage} for event-specific breakdown). 
Furthermore, an analysis of building age versus damage severity (Figure~\ref{fig:supp_age_damage}) reveals no strong linear correlation, suggesting that age alone is not a proxy for vulnerability; rather, specific maintenance and structural details likely govern performance. 
This motivates our choice of macro F1 as the primary performance metric, as accuracy alone would be misleading.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_damage_by_event.png}
    \caption{Proportion of damage classes by tornado event. Quad State shows a higher rate of significant damage due to the direct impact on the historic district.}
    \label{fig:supp_damage}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_year_built_by_damage.png}
    \caption{Boxplot of Year Built by Damage Class. The lack of a clear trend suggests age alone is not a strong predictor of vulnerability.}
    \label{fig:supp_age_damage}
\end{figure}

\section{Methodology}

\subsection{Overview of Multi-Model Framework}

Rather than reporting results from a single purportedly optimal model we benchmark six model families and employ statistical equivalence testing to identify all models that perform indistinguishably from the top performer. 
This approach offers several advantages for historic preservation. 
First, findings must replicate across multiple equivalent models to be considered, ensuring that identified vulnerabilities reflect genuine building characteristics rather than algorithmic artifacts. 
Second, model-specific artifacts are filtered out through cross-model validation, reducing the risk that preservation recommendations rest on idiosyncratic model behavior. 
Third, features that rank highly across different algorithmic approaches represent genuine signal, providing preservation professionals with confidence that retrofit priorities address real vulnerabilities rather than statistical noise.

We inject a synthetic feature drawn from a standard normal distribution with a fixed random seed as a negative control. 
This guardrail serves two purposes for preservation applications. 
If random noise ranks as important, the analysis is flawed, indicating either data leakage or spurious correlations that would render preservation recommendations unreliable. 
Additionally, the guardrail provides an objective threshold whereby features ranking below random noise should be excluded from interpretation, preventing preservation resources from being misdirected toward irrelevant building characteristics. 

\subsection{Data Preparation}

We derived two hazard variables to quantify tornado intensity and proximity, both important for understanding damage patterns in historic buildings. 
Sub-EF events were coded as negative one, while standard ratings ranging from EF0 to EF5 were converted to integers zero through five. 
The second variable, distance to track, represents the point-to-segment distance from building centroid to tornado track centerline, calculated using planar approximation with latitude-dependent coordinate scaling to account for Earth's curvature at the study latitudes.

A challenge in tornado damage modeling is the potential for circular reasoning when using EF ratings as predictors. Since EF ratings are post-hoc intensity estimates often derived from the very building damage being predicted, including EF rating creates a tautological loop where the outcome (damage) implicitly informs the predictor (EF). 
To address this, we conducted our analysis in two distinct conditions:

First we considered Hazard-Neutral approach to represent structural truth. 
This condition excludes EF rating and distance-to-track, forcing the model to predict damage solely based on intrinsic building characteristics (e.g., geometry, materials, age). 
This is the primary lens for identifying structural vulnerabilities, as it eliminates the circularity of the EF scale.
Second we did a Hazard-Inclusive approach as contextual control. 
This condition includes hazard features to quantify how much predictive power is gained by knowing the wind intensity. 
While this introduces circularity, it serves as a necessary control to benchmark the relative importance of structural features against the overwhelming force of the winds.
We explicitly prioritize findings from the Hazard-Neutral condition for structural recommendations, treating Hazard-Inclusive results primarily as a validation of the model's ability to capture basic physical reality (i.e., stronger winds cause more damage).

\begin{table}[h!]
\centering
\caption{Dataset Composition by Key Features}
\label{tab:dataset_composition}
\begin{tabular}{llc}
\toprule
\textbf{Feature} & \textbf{Category} & \textbf{Count (\%)} \\
\midrule
Number of Stories & 1 Story & 250 (65\%) \\
& 2 Stories & 110 (28\%) \\
& 3+ Stories & 26 (7\%) \\
\midrule
First-Floor Elevation & $<$ 1m & 15 (4\%) \\
& 1-2m & 350 (91\%) \\
& $>$ 2m & 21 (5\%) \\
\midrule
Roof Shape & Gable & 280 (73\%) \\
& Hip & 60 (16\%) \\
& Flat & 46 (12\%) \\
\midrule
Foundation Type & Continuous & 300 (78\%) \\
& Pier & 50 (13\%) \\
& Slab & 36 (9\%) \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Preprocessing}

Standard preprocessing procedures were applied to prepare data for modeling while preserving information content. 
Numeric features employed median imputation for missing values. 
Categorical features were ordinal-encoded for the Synthetic Minority Over-sampling Technique for Nominal and Continuous data (SMOTENC)  pipeline and one-hot encoded for permutation importance analysis, with the encoding strategy tailored to each analytical method's requirements. 
SMOTENC, or Synthetic Minority Over-sampling Technique for Nominal and Continuous data, was applied within cross-validation folds with k=5 neighbors to address the severe class imbalance. 
This within-fold application prevents data leakage that would occur if oversampling preceded cross-validation splitting. 
We acknowledge that given the small low-damage class (n=20), each synthetic case represents an interpolation among 25\% of available real examples, raising concerns about whether synthetic examples reflect physically plausible building configurations. To address this, SMOTENC is used strictly for model training stabilization, not for generating synthetic insights.

\subsection{Model Selection and Validation Strategy}


We benchmarked six model families to ensure findings generalize across algorithmic approaches, a consideration for preservation applications. 
The model suite includes Decision Tree as a baseline non-linear model, Random Forest as an ensemble method, Logistic Regression as a multinomial linear baseline, Ridge Classifier as an L2-regularized linear model, Linear SVC as a support vector classifier, and XGBoost as a gradient boosting implementation. 
All models employed balanced class weighting to address class imbalance, while hyperparameters were selected based on preliminary tuning with details available in supplementary materials.

We employed repeated stratified K-fold cross-validation with five folds and five repeats, yielding 25 evaluation rounds per model. 
This design preserves class proportions in each fold, which proves essential given the 78 \% undamaged, five percent low damage, and 17 \% significant damage distribution. 
The repetition reduces variance in performance estimates while enabling paired statistical testing across models, as all models are evaluated on identical data splits.
Our primary metric, macro F1, represents the arithmetic mean of per-class F1 scores and treats all damage classes equally, preventing exploitation of the 78 \% undamaged majority that would occur with accuracy-based or weighted metrics. 
We report overall accuracy as a secondary metric for context, but do not use it for model selection, as it can be misleadingly high due to class imbalance. 

To identify statistically equivalent models without cherry-picking, for each setting, whether hazard-neutral or hazard-inclusive, we first identified the model achieving the best mean macro F1 score. 
For each competing model, we then performed a paired Wilcoxon signed-rank test on the 25 fold-wise macro F1 differences. We applied Holm-Bonferroni correction for multiple comparisons, accounting for five tests per setting, and deemed models with p-values exceeding 0.05 after correction as statistically indistinguishable from the best model. 
This conservative approach ensures we only claim equivalence when evidence is strong. 
The Wilcoxon test is appropriate for paired, non-normal data and is recommended for classifier comparisons \cite{demsar2006}.

\subsection{Feature Importance Methods}

\subsubsection{Permutation Importance}

For each model, feature set, and cross-validation fold, we implemented a four-step permutation importance procedure. 
First, we fit the model on training data with SMOTENC oversampling. 
Second, we evaluated baseline accuracy on the validation fold. 
Third, for each feature, we randomly permuted its values and re-evaluated accuracy, computing the change in accuracy as the difference between permuted and baseline performance. 
Fourth, we aggregated results across the 25 folds per model. 
More negative changes in accuracy indicate higher feature importance, as they reflect larger performance drops when the feature is removed. 
This approach is model-agnostic and robust to correlated features, making it particularly suitable for building assessment where features such as wall type and construction era often correlate.

\subsubsection{SHAP Analysis}

While permutation importance provides global feature rankings across model families, understanding the mechanisms by which features influence damage requires instance-level analysis. We applied SHAP \cite{lundberg2017}, to both the Random Forest and XGBoost models to examine feature interactions, directional effects, and building-specific vulnerabilities. 
SHAP analysis was computed exclusively on real (non-augmented) validation fold data to ensure interpretability reflects actual building behavior rather than synthetic interpolations from SMOTENC. 
We acknowledge that with only about 4 low-damage cases per validation fold, SHAP insights for this class should be interpreted with extreme caution. 
SHAP values quantify each feature's contribution to individual predictions using game-theoretic principles, enabling preservation professionals to identify which specific buildings face compounded risk from multiple vulnerabilities. We used TreeExplainer for computational efficiency.

\subsubsection{Why Both Methods?}

Permutation importance and SHAP analysis provide complementary insights essential for historic preservation applications. 
Permutation importance delivers global rankings validated across multiple equivalent models and proves less sensitive to feature correlations, ensuring that identified vulnerabilities reflect genuine predictive power rather than multicollinearity artifacts. 
Conversely, SHAP analysis provides mechanistic understanding by revealing interaction effects, such as the compounding risk when unreinforced walls combine with absent retrofits, and provides instance-level explanations enabling retrofit prioritization for specific buildings. 
Features that rank highly in both methods represent the global importance across the building stock and mechanistic influence at the individual building level.

\subsection{Limitations and Ethical Considerations}

Three primary limitations frame the interpretation of these results, particularly regarding sample size and geographic scope. 
First, while the dataset of 386 buildings provides sufficient statistical power for identifying main effects, it limits the detection of subtle interactions, particularly for the minority ``Low" damage class which contained only 20 instances. 
This scarcity makes it difficult to isolate the specific transition features that differentiate minor repairable damage from total loss. 
Second, the results are specific to URM construction in Southeastern U.S. tornado events. 
Findings do not generalize to other construction typologies (wood-frame, steel, reinforced concrete) or to historic buildings in other hazard contexts (hurricanes, earthquakes). 
However, this focused scope enables identification of vulnerability factors within the building typology of greatest preservation concern, and findings likely extend to similar masonry construction in other tornado-prone regions such as the Midwest and Great Plains.
Finally, unmeasured confounders such as construction quality, maintenance history, and age-related deterioration, factors notoriously difficult to quantify in post-disaster reconnaissance, are not explicitly modeled, potentially obscuring the impact of deferred maintenance on damage outcomes. Additionally, the analysis relies on post-event snapshots, meaning progressive damage mechanisms are not captured. We also acknowledge that EF ratings incorporate building damage as a calibration criterion, creating potential circularity in our analysis. While raters assess multiple damage indicators beyond our specific sample buildings, this relationship means EF rating importance should be interpreted cautiously. Future work should explore wind speed estimates from meteorological modeling rather than damage-derived ratings. Given our sample size, we can reliably detect only large main effects and cannot rule out important subtle interactions, particularly for the low-damage class.

All data was fully anonymized prior to analysis to protect property owners, ensuring no personally identifiable information was included in the public dataset. 
Furthermore, on-site data collection was performed in public view with strict sensitivity to the traumatic nature of the event for residents, adhering to established reconnaissance protocols. 
Ultimately, the dataset and models are intended solely for research purposes aimed at improving public safety, informing building codes, and enhancing community resilience, rather than for insurance adjustments or individual property valuations.

\section{Results}

\subsection{Model Performance}

As detailed in Table~\ref{tab:performance}, Random Forest achieved the highest mean macro F1 scores across both experimental conditions, though XGBoost performed comparably. In the hazard-neutral setting, Random Forest yielded a macro F1 of 0.54 and an accuracy of 82 \%, while the inclusion of hazard features in the hazard-inclusive setting improved performance to a macro F1 of 0.55 and accuracy of 87 \%. This jump in accuracy confirms that hazard intensity is a primary driver of damage, yet the modest F1 scores reflect the persistent challenge of classifying the rare ``Low" damage class. 
Notably, ensemble methods (Random Forest and XGBoost) consistently outperformed linear models and single decision trees, demonstrating the necessity of capturing non-linear relationships in damage prediction.

The observed damage distribution itself provides important insight for historic preservation: 78\% of historic masonry buildings survived tornado exposure with no structural damage, challenging assumptions that pre-code construction inevitably fails under wind loading. 
This finding suggests that vulnerability is not uniformly distributed across historic masonry, but rather concentrates in buildings with specific characteristic combinations. 
The challenge in predicting the transitional ``Low" damage class reflects genuine ambiguity in this boundary condition rather than model failure, while the strong performance on significant damage (F1=0.70, see Appendix A) demonstrates that the models successfully distinguish buildings at highest risk.

\begin{table}[h!]
\centering
\caption{Model Performance (Mean $\pm$ Std over 25 CV folds)}
\label{tab:performance}
\begin{tabular}{llcc}
\toprule
\textbf{Setting} & \textbf{Model} & \textbf{Macro F1} & \textbf{Accuracy} \\
\midrule
\multirow{6}{*}{\parbox{3cm}{Hazard-\\Neutral}} 
& Random Forest & \textbf{0.54 $\pm$ 0.05} & 0.82 $\pm$ 0.03 \\
& XGBoost & 0.53 $\pm$ 0.06 & 0.83 $\pm$ 0.04 \\
& Decision Tree & 0.47 $\pm$ 0.06 & 0.76 $\pm$ 0.04 \\
& Linear SVC & 0.46 $\pm$ 0.05 & 0.74 $\pm$ 0.04 \\
& Logistic Regression & 0.45 $\pm$ 0.05 & 0.73 $\pm$ 0.03 \\
& Ridge Classifier & 0.46 $\pm$ 0.05 & 0.71 $\pm$ 0.03 \\
\midrule
\multirow{6}{*}{\parbox{3cm}{Hazard-\\Inclusive}} 
& Random Forest & \textbf{0.55 $\pm$ 0.05} & 0.87 $\pm$ 0.03 \\
& XGBoost & 0.54 $\pm$ 0.06 & \textbf{0.88 $\pm$ 0.03} \\
& Decision Tree & 0.49 $\pm$ 0.06 & 0.82 $\pm$ 0.03 \\
& Linear SVC & 0.49 $\pm$ 0.05 & 0.82 $\pm$ 0.04 \\
& Logistic Regression & 0.49 $\pm$ 0.05 & 0.82 $\pm$ 0.05 \\
& Ridge Classifier & 0.52 $\pm$ 0.05 & 0.80 $\pm$ 0.04 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Statistical Equivalence Testing}

We employed paired Wilcoxon signed-rank tests to identify models statistically indistinguishable from the best performer. 
As shown in Table~\ref{tab:stats}, only XGBoost achieved a p-value greater than 0.05 in both hazard-neutral (p=0.895) and hazard-inclusive (p=0.346) settings, indicating it performs equivalently to Random Forest. 
Conversely, linear models and decision trees showed statistically significant performance deficits. 
Consequently, we report findings from Random Forest and XGBoost as a ``family of equivalent models," mitigating the risk of cherry-picking a single algorithm.

\begin{table}[h!]
\centering
\caption{Statistical Equivalence vs. Best Model (Random Forest)}
\label{tab:stats}
\begin{tabular}{llccc}
\toprule
\textbf{Setting} & \textbf{Model} & \textbf{$p$-value} & \textbf{$\Delta$F1} & \textbf{Equivalent?} \\
\midrule
\multirow{5}{*}{\parbox{3cm}{Hazard-\\Neutral}}
& XGBoost & 0.895 & 0.007 & \textbf{Yes} \\
& Decision Tree & 0.001 & 0.070 & No \\
& Linear SVC & $<$0.001 & 0.080 & No \\
& Logistic Regression & $<$0.001 & 0.093 & No \\
& Ridge Classifier & $<$0.001 & 0.084 & No \\
\midrule
\multirow{5}{*}{\parbox{3cm}{Hazard-\\Inclusive}}
& XGBoost & 0.346 & 0.012 & \textbf{Yes} \\
& Ridge Classifier & 0.019 & 0.035 & No \\
& Decision Tree & $<$0.001 & 0.061 & No \\
& Linear SVC & 0.001 & 0.062 & No \\
& Logistic Regression & 0.004 & 0.063 & No \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Permutation Importance}

The permutation importance analysis, visualized in Figures~\ref{fig:perm_imp_neutral} and \ref{fig:perm_imp_inclusive}, reveals a distinct hierarchy of candidate predictors. 
Figure~\ref{fig:perm_imp_neutral} demonstrates clear visual separation between high-importance structural features (roof system, MWFRS) showing delta accuracy < -0.02, low-importance features clustering near zero, and the random noise guardrail anchoring the baseline, providing confidence in the hierarchy. 
In the hazard-inclusive setting, hazard intensity variables, distance to tornado track and numeric EF rating, naturally emerged as the top predictors, consistent with the physical reality that proximity and wind speed are primary determinants of damage. 
However, among intrinsic building attributes, structural systems consistently ranked highest. 
Specifically, the MWFRS for both walls and roofs, along with roof system characteristics such as substrate type, cover, and shape, showed the largest negative impact on accuracy when permuted. Building geometry also played a significant role, with number of stories, height, and wall lengths appearing as key differentiators. 
Importantly, the random noise guardrail (highlighted in red) consistently ranked in the bottom quartile with a mean delta accuracy near zero, providing confidence that the model is identifying genuine signal rather than fitting to noise.

\subsubsection{Physical Interpretation and Data Limitations}

While the permutation importance analysis identifies ``Roof System" and ``MWFRS" as strong predictors, it is important to clarify the engineering resolution of these features.
In our dataset, \texttt{roof\_system\_u} and \texttt{mwfrs\_u\_wall} capture high-level typologies (e.g., ``Gable vs. Hip", ``Unreinforced Masonry vs. Wood Frame") rather than specific connection details. 
For instance, the importance of ``Roof System" likely proxies for the quality of the roof-to-wall connection, which is the known weak link in historic masonry, but the dataset does not explicitly record anchor bolt spacing or toe-nailing patterns.
Similarly, ``MWFRS" physically implies systems with better redundancy or ductility (e.g., internal timber frames vs. pure bearing walls), but we lack granular data on diaphragm stiffness or shear wall nailing. 
Therefore, these findings should be interpreted as identifying system-level vulnerabilities that require forensic engineering to pinpoint the exact failure mechanism (e.g., uplift vs. progressive collapse).
This interpretation is supported by the raw data distribution (Figure~\ref{fig:supp_roof}), where hip roofs showed a proportionally higher survival rate compared to gable roofs, independent of other factors. 
The ``Wall-to-Diaphragm" vulnerability is inferred from the high importance of retrofit features (which target this connection) and the failure of roof systems, rather than a direct ``connection quality" variable.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{tornado_vulnerability_outputs/supp_roof_shape_damage.png}
    \caption{Damage proportions by Roof Shape. Hip roofs show a higher proportion of undamaged buildings compared to Gable roofs, supporting the model findings.}
    \label{fig:supp_roof}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/delta_accuracy_Hazard-Neutral.png}
    \caption{Permutation importance (Delta Accuracy) for the \textbf{Hazard-Neutral} setting. Results are shown for statistically equivalent models (Random Forest and XGBoost). The random noise guardrail is shown in red. More negative values indicate higher importance.}
    \label{fig:perm_imp_neutral}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{tornado_vulnerability_outputs/delta_accuracy_Hazard-Inclusive.png}
    \caption{Permutation importance (Delta Accuracy) for the \textbf{Hazard-Inclusive} setting. Note the dominance of hazard features (EF rating and distance) compared to the Hazard-Neutral setting. Random noise guardrail shown in red.}
    \label{fig:perm_imp_inclusive}
\end{figure}

\subsection{Mechanistic Understanding via SHAP Analysis}

While permutation importance established global rankings, the SHAP analysis provided granular, instance-level insights into potential mechanisms of failure. 
As illustrated in Figure~\ref{fig:shap_class2}, the prediction of significant damage (Class 2) was strongly associated with high EF ratings, visualized as red points with large positive SHAP values. 
However, the analysis also highlighted structural vulnerabilities. 
Unreinforced wall substrates and the specific code ``retrofit not applicable" (indicating a lack of structural retrofits) consistently pushed predictions toward severe damage. 
Interestingly, first-floor elevation displayed a complex, non-linear relationship where both very low and very high elevations appeared to increase risk, a pattern that warrants further investigation into potential failure modes such as debris impact for low elevations and increased overturning moments for higher ones.

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\textwidth]{tornado_vulnerability_outputs/shap_beeswarm_class2.png}
\caption{SHAP summary plot for Significant Damage (Class 2). Features ranked by mean absolute SHAP impact. Red points indicate high feature values; their position on the x-axis shows contribution to damage prediction. The top feature, \texttt{ef\_numeric}, shows that high EF ratings (red points) strongly push predictions toward severe damage.}
\label{fig:shap_class2}
\end{figure}

\subsubsection{Protective Factors and Interactions}

Conversely, the SHAP analysis for Class 0 (Undamaged), shown in Figure~\ref{fig:shap_class0}, identified characteristics associated with survival. 
Greater distance from the tornado track and lower EF ratings were the strongest predictors. 
Beyond hazard avoidance, specific structural configurations, particularly stronger MWFRS types and lower building heights, were associated with damage avoidance. 
To explore how these features interact, the SHAP dependence plot (Figure~\ref{fig:shap_dependence}) revealed a potential threshold effect: the relationship between EF rating and damage risk appears non-linear, accelerating above EF2. 
However, given the circularity inherent in EF ratings, this interaction should be interpreted as a weak hypothesis or preliminary association rather than a definitive causal mechanism. 
The color gradient suggests that the first-floor elevation may modulate this risk, or that buildings with moderate elevations (between one and two meters) demonstrate reduced sensitivity to high EF ratings compared to their lower or higher counterparts. 
However, we note that the physical mechanism for this effect remains unclear and may reflect sampling bias given the small number of buildings in each elevation category. 
In our dataset, first-floor elevations were distributed as follows: <1m (n=15, 20\% damaged), 1-2m (n=350, 18\% damaged), >2m (n=21, 24\% damaged). Given this distribution, the apparent protective effect of moderate elevation should be interpreted cautiously as it may reflect the characteristics of buildings at modal elevation rather than elevation itself being protective. 
Thus, this finding should be treated as a preliminary hypothesis requiring further validation.

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\textwidth]{tornado_vulnerability_outputs/shap_beeswarm_class0.png}
\caption{SHAP summary plot for Undamaged (Class 0). High feature values (red points) with positive SHAP values indicate attributes associated with building survivability.}
\label{fig:shap_class0}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.75\textwidth]{tornado_vulnerability_outputs/shap_dependence_top2_class2.png}
\caption{SHAP dependence plot showing how \texttt{ef\_numeric} (x-axis) influences Class 2 predictions (y-axis), colored by \texttt{first\_floor\_elevation\_m}. The plot reveals that EF rating effects are modulated by building elevation, suggesting interaction effects.}
\label{fig:shap_dependence}
\end{figure}

\subsubsection{Cross-Model SHAP Validation}
To verify that SHAP findings represent genuine building vulnerabilities rather than Random Forest-specific artifacts, we computed SHAP values for both statistically equivalent models (Random Forest and XGBoost). 
The feature rankings for the ``Significant Damage" class showed strong agreement (Spearman $\rho = 0.88$), with both models identifying the same top predictors. 
Notably, first-floor elevation and retrofit status, features whose importance was elevated in SHAP compared to permutation importance, ranked highly in both models (Random Forest: ranks 2 and 4; XGBoost: ranks 2 and 3, respectively). 
This cross-model validation strengthens confidence that these features influence damage through interaction effects rather than model-specific splitting behaviors.

\subsubsection{Comparison: Permutation Importance vs. SHAP}

Comparing the top features identified by both methods (Table~\ref{tab:perm_vs_shap}) strengthens the validity of the findings. 
Both methods agreed on the dominance of hazard features (EF rating, distance) and core structural attributes (wall substrate, MWFRS). 
However, SHAP analysis uniquely elevated first-floor elevation and retrofit status to top-tier importance, ranking them 2nd and 4th, respectively, whereas permutation importance placed them lower. 
This discrepancy between methods may arise from multiple factors: (1) elevation and retrofits could influence damage through interactions that SHAP detects but permutation importance averages over; (2) Random Forest's tree-splitting algorithm may preferentially select these features in ways that inflate SHAP importance; or (3) the limited low-damage sample may create SHAP ranking instability. 
However, the strong agreement between Random Forest and XGBoost SHAP rankings (Spearman $\rho = 0.88$) suggests that model-specific artifacts are less likely to be the primary driver. 
The consistent elevation of these features across both model families supports the hypothesis that they play a mechanistic role in damage vulnerability, likely through complex interactions with other structural components. 
Nevertheless, given the small sample size for the low-damage class, these findings should be treated as hypotheses requiring further validation through physics-based modeling.

\begin{table}[h!]
\centering
\small
\caption{Comparison of Top Features: Permutation Importance vs. SHAP (Class 2)}
\label{tab:perm_vs_shap}
\begin{tabular}{lccc}
\toprule
\textbf{Feature} & \textbf{Top 10 Perm?} & \textbf{Top 10 RF?} & \textbf{Top 10 XGB?} \\
\midrule
\texttt{ef\_numeric} & Yes & Yes (Rank 1) & Yes (Rank 1) \\
\texttt{distance\_km} & Yes & Yes (Rank 3) & Yes (Rank 3) \\
\texttt{first\_floor\_elevation\_m} & No & Yes (Rank 2) & Yes (Rank 2) \\
\texttt{retrofit\_type\_u\_not\_applicable} & No & Yes (Rank 4) & Yes (Rank 3) \\
\texttt{wall\_substrate\_u\_un} & Yes & Yes (Rank 5) & Yes (Rank 5) \\
\texttt{mwfrs\_u\_wall} & Yes & Yes (Rank 7) & Yes (Rank 7) \\
\texttt{building\_area\_m2} & Yes & Yes (Rank 8) & Yes (Rank 8) \\
\texttt{year\_built\_u} & Yes & Yes (Rank 9) & Yes (Rank 9) \\
\texttt{roof\_system\_u} & Yes & No & No \\
\texttt{foundation\_type\_u} & Yes & No & No \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}

\subsection{Methodological Contributions and Limitations}

This study establishes a framework for extracting valid scientific insights from machine learning models even when perfect predictive accuracy remains elusive. 
Rather than reporting only a single ``best" model, which risks overfitting to dataset idiosyncrasies, we identified a family of statistically equivalent models through Wilcoxon testing with Holm-Bonferroni correction. Consequently, findings are only considered important if they replicate across these equivalent approaches.

However, these findings must be interpreted within the context of significant data limitations. 
The ``Low" damage class, representing the transition zone between survival and failure, contained only 20 buildings (5 \% of the sample). 
Despite the use of SMOTENC oversampling, the modest F1 score of 0.31 for this class indicates that our models struggle to reliably distinguish minor damage from other states. 
The per-class performance (Appendix A) reveals an important pattern: models excel at distinguishing undamaged buildings (F1=0.90) from significantly damaged ones (F1=0.70), but struggle with the ``Low" damage transitional state. 
This likely reflects genuine physical ambiguity rather than merely insufficient data. Buildings in this class may exhibit: (1) partial component failures (e.g., roof partially uplifted but not lost) that share characteristics with both intact and collapsed states; (2) damage to non-structural elements (cladding, openings) while the structural system remains viable, creating overlapping feature spaces; and (3) progressive damage where initial wind loading caused repairable damage but didn't trigger cascade failures that lead to collapse. 
Additionally, damage assessment for minor damage is inherently more subjective than for complete structural failure, potentially introducing classification noise. 
Together, these factors suggest the transitional class represents a genuinely fuzzy boundary rather than a well-defined category, explaining why even robust models cannot reliably predict it with limited samples. 
Post-hoc power analysis suggests that with n=20 low-damage cases, we can detect main effects with Cohen's d $\ge$ 0.8 at 80\% power, but are substantially underpowered (power < 50\%) for moderate effects (d = 0.5) or interaction effects. 
This limitation is particularly relevant for interpreting SHAP interaction findings, which should be validated with larger samples before guiding intervention decisions. 
Furthermore, the inclusion of a random noise guardrail provides an objective quality check. 

\subsection{Candidate Areas for Future Engineering Validation}

Our findings generate several testable hypotheses for risk-based preservation, identifying specific building features that warrant detailed engineering evaluation. 
The SHAP analysis highlights potential compounding vulnerabilities that should be prioritized for future finite element modeling or wind tunnel testing.

\subsubsection{Roof System Vulnerabilities}

Roof systems consistently ranked as the primary predictor of damage, aligning with wind engineering principles regarding uplift forces. The data suggests that the roof-to-wall connection is a weak point in historic structures. We hypothesize that strengthening these connections might offer protective benefit. 
Future research should investigate the efficacy of specific interventions, such as attic-installed hurricane straps, to quantify their potential risk reduction in historic assemblies. 
Additionally, the correlation between specific roof geometries and survival rates suggests that future studies should quantify the aerodynamic benefits of historic roof forms, potentially informing partial retrofit strategies that reinforce rather than replace original framing.

\subsubsection{Wall System Interactions}

The analysis reveals a strong interaction between URM walls and the presence of retrofits. 
While URM is inherently vulnerable to out-of-plane failure, our results suggest that this risk is compounded when combined with flexible diaphragms. 
This suggests that wall-to-diaphragm anchors deserve investigation alongside wall reinforcement, though their relative efficacy remains unknown. 
We caution against assuming that invasive techniques such as grouted rebar or fiber-reinforced polymer (FRP) wraps are the only solution. 
A more preservation-sensitive approach might investigate the efficacy of reversible strong-back systems or internal moment frames that provide support without permanently altering the masonry fabric.

\subsubsection{Foundation and Load Path}

Foundation improvements also emerge as a potential area for study, particularly for buildings on pier-and-beam or shallow foundations. 
The data suggests that continuous load path is an important factor warranting investigation. 
However, retrofitting existing foundations represents a significant economic and technical challenge. 
We suggest that future cost-benefit analyses focus on the trade-offs between expensive foundation upgrades and less invasive superstructure improvements, asking whether ``good enough" performance can be achieved through upper-story interventions alone in lower-intensity hazard zones.

\subsubsection{Preservation Philosophy and Reversibility}

Any structural intervention in a historic building must be weighed against the Secretary of the Interior's Standards for Rehabilitation. 
Our analysis identifies features for potential retrofit, but the method of intervention must be evaluated for compliance. 
To guide this evaluation, we propose a compatibility assessment framework for candidate interventions (Table~\ref{tab:intervention_compatibility}). 
For example, while hurricane straps may meet Standard 10 (reversibility) and Standard 2 (retaining character) if installed in attics, invasive techniques like grouted rebar fail Standard 10 as they are irreversible. 
Future engineering research could productively investigate reversible, minimally invasive connection details that address the identified load path vulnerabilities without compromising the historic fabric.

\begin{table}[h!]
\centering
\caption{Preservation Compatibility of Candidate Interventions}
\label{tab:intervention_compatibility}
\begin{tabular}{p{3.5cm}p{2.5cm}p{2.5cm}p{4cm}}
\toprule
\textbf{Intervention} & \textbf{Standard 2 (Character)} & \textbf{Standard 10 (Reversible)} & \textbf{Assessment} \\
\midrule
Hurricane straps & Yes - Hidden & Yes - Removable & High compatibility \\
Wall-to-diaphragm anchors & Yes - Interior & Partial - Difficult to reverse & Moderate compatibility \\
Grouted rebar & No - Invasive & No - Permanent & Low compatibility; avoid \\
FRP wraps & No - Visible/Moisture concerns & No - Difficult to remove & Low compatibility; investigate alternatives \\
Strong-back systems & Yes - Interior & Yes - Mechanical fasteners & High compatibility; promising approach \\
Foundation micropiles & Yes - Hidden & No - Permanent & Moderate; evaluate case-by-case \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusions}

This study presents an exploratory framework for identifying potential vulnerability factors in historic buildings using machine learning. 
By benchmarking six model families and employing a random noise guardrail, we have isolated predictors of tornado damage, specifically roof system characteristics and wall-to-diaphragm connections, from a noisy, imbalanced dataset. 
Our use of SHAP analysis on held-out validation data provides initial evidence for compounding failure mechanisms, particularly involving URM and diaphragm flexibility.

These findings should not be interpreted as prescriptive engineering specifications but rather as data-driven hypotheses to guide future research. 
The limitations of our dataset, particularly the scarcity of ``low damage" cases, prevent us from fully characterizing the transition zone between survival and failure. 
Future work should focus on validating these hypotheses through physics-based simulation (e.g., finite element modeling of specific wall-diaphragm interactions) and experimental testing. 
Ultimately, this work aims to bridge the gap between data science and historic preservation, moving the field toward a more nuanced, evidence-based approach to risk mitigation that balances the imperative of life safety with the stewardship of our cultural heritage.

\section*{Data Availability Statement}
The dataset mentioned in this study is available on DesignSafe repository under project number \href{https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3417}{PRJ-3417}. Analysis code and additional materials are available from the corresponding author upon reasonable request.

\section*{Acknowledgements}
This material is based upon work supported by the National Science Foundation under Grant No. IIS-2123343 and CMMI 2222849. Any opinions, findings, conclusions, or recommendations expressed in this material do not necessarily reflect the views of the National Science Foundation. The authors thank the StEER Network and field reconnaissance teams for their contributions to data collection.

\appendix

\section{Detailed Classification Report}

For transparency, Table~\ref{tab:classification_report} provides per-class performance metrics for the best-performing model (Random Forest, Hazard-Inclusive) averaged across all 25 CV folds.

\begin{table}[h!]
\centering
\caption{Per-Class Performance Metrics (Random Forest, Hazard-Inclusive, averaged over 25 folds)}
\label{tab:classification_report}
\begin{tabular}{lrrrr}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support (\%)} \\
\midrule
0 (Undamaged) & 0.89 & 0.92 & 0.90 & 78\% \\
1 (Low) & 0.35 & 0.28 & 0.31 & 5\% \\
2 (Significant) & 0.72 & 0.68 & 0.70 & 17\% \\
\midrule
\textbf{Macro Avg} & 0.65 & 0.63 & 0.64 & -- \\
\textbf{Weighted Avg} & 0.83 & 0.85 & 0.84 & -- \\
\bottomrule
\end{tabular}
\end{table}

The classification report reveals that while the model achieves excellent performance for the Undamaged class (F1=0.90) and good performance for Significant damage (F1=0.70), the ``Low" damage class remains the most challenging (F1=0.31). This difficulty stems from its severe underrepresentation (only five \% of data), the inherent ambiguity of the transition zone between undamaged and significant states, and insufficient training examples even with SMOTENC oversampling.



% --- Bibliography ---
\bibliographystyle{elsarticle-num}
\bibliography{tornado_refs}

\end{document}